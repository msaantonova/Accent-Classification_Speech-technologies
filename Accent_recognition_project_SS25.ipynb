{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msaantonova/Accent-Classification_Speech-technologies/blob/main/Accent_recognition_project_SS25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. So at first I've just copied the colab that was mentioned in the PDF task (so that we could later loadthe database)"
      ],
      "metadata": {
        "id": "HJdSuGWIi7a9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repository from the paper\n",
        "\n",
        "\"This repository provides all the necessary tools to perform accent identification from speech recordings with SpeechBrain toolkit! The system uses a model fine-tuned on the CommonAccent dataset in English (21 accents). The provided system can recognize the following 21 accents of English from short speech recordings\""
      ],
      "metadata": {
        "id": "6uOohfJNCNLx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvKoxtf7-l7s",
        "outputId": "66abc8ff-41dc-40a3-f89c-63e273c9d534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'accent-recog-slt2022'...\n",
            "remote: Enumerating objects: 527, done.\u001b[K\n",
            "remote: Counting objects: 100% (204/204), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 527 (delta 182), reused 155 (delta 154), pack-reused 323 (from 1)\u001b[K\n",
            "Receiving objects: 100% (527/527), 2.64 MiB | 12.27 MiB/s, done.\n",
            "Resolving deltas: 100% (342/342), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lgspeech/accent-recog-slt2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAG2EUzBeABn",
        "outputId": "8a51a48d-c1eb-4089-c66b-4f52815b069b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/accent-recog-slt2022\n",
            "Ignoring SoundFile: markers 'sys_platform == \"win32\"' don't match your environment\n",
            "Collecting speechbrain==0.5.13 (from -r requirements.txt (line 1))\n",
            "  Downloading speechbrain-0.5.13-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting datasets==2.8.0 (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting transformers==4.25.1 (from -r requirements.txt (line 3))\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting librosa==0.9.2 (from -r requirements.txt (line 4))\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting ipdb>=0.13.9 (from -r requirements.txt (line 5))\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.33.0)\n",
            "Collecting hyperpyyaml>=0.0.1 (from -r requirements.txt (line 8))\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (24.2)\n",
            "Collecting pre-commit>=2.3.0 (from -r requirements.txt (line 12))\n",
            "  Downloading pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting scipy<1.9,>=1.4.1 (from -r requirements.txt (line 13))\n",
            "  Downloading scipy-1.6.1.tar.gz (27.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.6.0+cu124)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchaudio<=0.11.0,>=0.9.0 (from versions: 2.0.1, 2.0.2, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchaudio<=0.11.0,>=0.9.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%cd /content/accent-recog-slt2022\n",
        "!python -m pip install -r requirements.txt\n",
        "# you can ignore any errors for now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQrLs6ilfGon",
        "outputId": "7309d5af-fc2a-4b57-df46-0470df18b0e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/474.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/177.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.6.1 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets==3.0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change working directory:\n",
        "%cd CommonAccent/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m6-V5CHYS-V",
        "outputId": "40e143d6-12fc-4816-a541-1dd5dd62a371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/accent-recog-slt2022/CommonAccent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the data (or stream) and create the list of filtered items\n",
        "\n",
        "You can either use streaming, or save the files locally. you can check at common voice, how big the corpus for each language is.\n",
        "If you use streaming, it  will take a few hours.\n",
        "\n",
        "The aim of it is to create lists of all audios that have marked accent in the metadata, so you can choose which ones of these you want for classification."
      ],
      "metadata": {
        "id": "gAQzxiFMYUnj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAt-X0eXezdf",
        "outputId": "14022fc3-95c1-4a96-9a3d-884c9a4efabc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common_voice_19_0.py: 100% 8.17k/8.17k [00:00<00:00, 33.2MB/s]\n",
            "README.md: 100% 4.47k/4.47k [00:00<00:00, 19.0MB/s]\n",
            "languages.py: 100% 4.00k/4.00k [00:00<00:00, 23.3MB/s]\n",
            "release_stats.py: 100% 138k/138k [00:00<00:00, 1.81MB/s]\n",
            "n_shards.json: 100% 16.5k/16.5k [00:00<00:00, 51.0MB/s]\n",
            "it_train_0.tar: 100% 1.69G/1.69G [00:15<00:00, 112MB/s]\n",
            "it_train_1.tar: 100% 1.58G/1.58G [00:18<00:00, 83.6MB/s]\n",
            "it_train_2.tar: 100% 1.38G/1.38G [00:13<00:00, 99.3MB/s]\n",
            "it_train_3.tar: 100% 1.32G/1.32G [00:13<00:00, 94.7MB/s]\n",
            "it_train_4.tar: 100% 374M/374M [00:02<00:00, 138MB/s]\n",
            "it_dev_0.tar: 100% 703M/703M [00:06<00:00, 115MB/s]\n",
            "it_test_0.tar: 100% 743M/743M [00:08<00:00, 84.5MB/s]\n",
            "it_other_0.tar: 100% 443M/443M [00:11<00:00, 38.8MB/s]\n",
            "it_invalidated_0.tar: 100% 875M/875M [00:13<00:00, 65.6MB/s]\n",
            "train.tsv: 100% 54.7M/54.7M [00:01<00:00, 47.9MB/s]\n",
            "dev.tsv: 100% 4.65M/4.65M [00:00<00:00, 18.1MB/s]\n",
            "test.tsv: 100% 4.62M/4.62M [00:00<00:00, 16.5MB/s]\n",
            "other.tsv: 100% 3.90M/3.90M [00:00<00:00, 21.7MB/s]\n",
            "invalidated.tsv: 100% 6.41M/6.41M [00:00<00:00, 17.5MB/s]\n",
            "Generating train split: 0 examples [00:00, ? examples/s]\n",
            "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
            "Reading metadata...: 12721it [00:00, 127194.96it/s]\u001b[A\n",
            "Reading metadata...: 25441it [00:00, 124378.71it/s]\u001b[A\n",
            "Reading metadata...: 37884it [00:00, 119890.89it/s]\u001b[A\n",
            "Reading metadata...: 50198it [00:00, 121130.79it/s]\u001b[A\n",
            "Reading metadata...: 62325it [00:00, 118480.94it/s]\u001b[A\n",
            "Reading metadata...: 74188it [00:00, 117319.74it/s]\u001b[A\n",
            "Reading metadata...: 85929it [00:00, 116333.91it/s]\u001b[A\n",
            "Reading metadata...: 97568it [00:00, 110856.45it/s]\u001b[A\n",
            "Reading metadata...: 109238it [00:00, 112591.92it/s]\u001b[A\n",
            "Reading metadata...: 120536it [00:01, 112049.54it/s]\u001b[A\n",
            "Reading metadata...: 132197it [00:01, 113403.35it/s]\u001b[A\n",
            "Reading metadata...: 143678it [00:01, 113819.63it/s]\u001b[A\n",
            "Reading metadata...: 155076it [00:01, 113670.51it/s]\u001b[A\n",
            "Reading metadata...: 171388it [00:01, 115616.49it/s]\n",
            "Generating train split: 171388 examples [00:49, 3462.82 examples/s]\n",
            "Generating validation split: 0 examples [00:00, ? examples/s]\n",
            "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
            "Reading metadata...: 15162it [00:00, 121083.30it/s]\n",
            "Generating validation split: 15162 examples [00:05, 2738.02 examples/s]\n",
            "Generating test split: 0 examples [00:00, ? examples/s]\n",
            "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
            "Reading metadata...: 15167it [00:00, 122645.29it/s]\n",
            "Generating test split: 15167 examples [00:04, 3438.63 examples/s]\n",
            "Generating other split: 0 examples [00:00, ? examples/s]\n",
            "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
            "Reading metadata...: 12189it [00:00, 115558.28it/s]\n",
            "Generating other split: 12189 examples [00:03, 3834.73 examples/s]\n",
            "Generating invalidated split: 0 examples [00:00, ? examples/s]\n",
            "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
            "Reading metadata...: 20123it [00:00, 118351.45it/s]\n",
            "Generating invalidated split: 20123 examples [00:06, 2945.85 examples/s]\n",
            "Filter: 100% 171388/171388 [24:25<00:00, 116.94 examples/s]\n",
            "Filter: 100% 15162/15162 [01:59<00:00, 126.37 examples/s]\n",
            "Filter: 100% 15167/15167 [02:12<00:00, 114.07 examples/s]\n",
            "Prepare CommonVoice: for it in data/cv_11/it\n"
          ]
        }
      ],
      "source": [
        "#!python download_data_hf.py --language \"it\" data/cv_11/  #this part descrbes the dataset index and the language\n",
        "!python download_data_hf.py --language \"it\" data/cv_11/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the filtered list to be used in this model --> create csv files in correct form"
      ],
      "metadata": {
        "id": "xDqntrpPYjUn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Zgu6_R0J6dP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc04089-ad19-4fff-e327-afdcbb27867a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/499.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.0/499.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m5.0/5.8 MB\u001b[0m \u001b[31m150.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/214.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q speechbrain==0.5.13 \\\n",
        "    transformers==4.25.1 \\\n",
        "    librosa==0.9.2 \\\n",
        "    ipdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python common_accent_prepare.py --language \"it\" data/cv_11 data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ25UXrSYQpI",
        "outputId": "30c642e0-3966-4866-bb62-214ed3ebd70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/cv_11 ['.mp3'] it\n",
            "/content/accent-recog-slt2022/CommonAccent/data/cv_11/it/validation.tsv\n",
            "/content/accent-recog-slt2022/CommonAccent/data/cv_11/it/test.tsv\n",
            "/content/accent-recog-slt2022/CommonAccent/data/cv_11/it/train.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "from datasets import load_dataset\n",
        "\n",
        "data_path = \"/content/accent-recog-slt2022/CommonAccent/data/\"\n",
        "# Load CSV\n",
        "csv_path_train = data_path + \"train.csv\"\n",
        "df_train = pd.read_csv(csv_path_train)\n",
        "file_list_train = list(set(df_train['wav']))\n",
        "\n",
        "csv_path_test = data_path + \"test.csv\"\n",
        "df_test = pd.read_csv(csv_path_test)\n",
        "file_list_test = list(set(df_test['wav']))\n",
        "\n",
        "csv_path_dev = data_path + \"dev.csv\"\n",
        "df_dev = pd.read_csv(csv_path_dev)\n",
        "file_list_dev = list(set(df_dev['wav']))\n",
        "\n",
        "# Set save directory\n",
        "save_dir = data_path + \"wav_files\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Load dataset in streaming mode\n",
        "language = \"it\"  # or whatever language code you're using\n",
        "cv_19_train = load_dataset(\"fsicoli/common_voice_19_0\", language, streaming=True, split=\"train\", trust_remote_code=True)\n",
        "print(next(iter(cv_19_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pHghJSvEuEq",
        "outputId": "6ad6a31e-3f22-402f-fd92-e8410005b469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Reading metadata...: 171388it [00:07, 23662.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'client_id': 'c14f21cacf2b7701ad0bead0dd1b31ec9d3a1557708e446de55e98b4b470cf31072c82543e5ba518c5c187a91868878a4e32727054a3dd94f9df41c9a13d8c62', 'path': 'it_train_0/common_voice_it_17415777.mp3', 'audio': {'path': 'it_train_0/common_voice_it_17415777.mp3', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
            "       -1.61342832e-05, -1.57291943e-05, -1.16234423e-05]), 'sampling_rate': 48000}, 'sentence': \"Il marchese aveva già moglie in quell'epoca?\", 'up_votes': 3, 'down_votes': 0, 'age': '', 'gender': '', 'accent': '', 'locale': 'it', 'segment': '', 'variant': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_19_dev = load_dataset(\"fsicoli/common_voice_19_0\", language, streaming=False, split=\"validation\", trust_remote_code=True)\n",
        "cv_19_test = load_dataset(\"fsicoli/common_voice_19_0\", language, streaming=False, split=\"test\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "PMZFhNN_V2Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Count entries per accent\n",
        "accent_counts = df_train['accent'].value_counts()\n",
        "\n",
        "# Print the result\n",
        "print(accent_counts)\n",
        "\n",
        "# select randomly max 300 samples for each accent that has more than 300 samples\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Uyu3fx-SAlo",
        "outputId": "003c3702-9ce5-40c1-8950-9693771089f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accent\n",
            "TENDENTE AL SICULO MA NON MARCATO    1801\n",
            "BASILICATA TRENTINO                  1801\n",
            "VENETO                               1393\n",
            "MERIDIONALE                           134\n",
            "EMILIANO                               91\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code adjusts the audio paths and can be used for balancing the data:"
      ],
      "metadata": {
        "id": "1bk_7sQqCp-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# add /content/accent-recog-slt2022/CommonAccent/data_small to each \"wav\" in the csv .../train.csv\n",
        "save_dir_colab = data_path\n",
        "# \"content/accent-recog-slt2022/CommonAccent/data_small/\"\n",
        "df_train['wav'] = df_train['wav'].apply(lambda x: os.path.join(save_dir_colab, x))\n",
        "df_test['wav'] = df_test['wav'].apply(lambda x: os.path.join(save_dir_colab, x))\n",
        "df_dev['wav'] = df_dev['wav'].apply(lambda x: os.path.join(save_dir_colab, x))\n",
        "df_train.to_csv(csv_path_train, index=False)\n",
        "\n",
        "# show all available accents\n",
        "accent_counts = df_train['accent'].value_counts()\n",
        "\n",
        "# Print the result\n",
        "print(accent_counts)\n",
        "\n",
        "# select randomly max 300 samples for each accent\n",
        "df_train2 = df_train.groupby('accent').apply(lambda x: x.sample(min(len(x), 300), random_state=1)).reset_index(drop=True)\n",
        "df_dev2 = df_dev.groupby('accent').apply(lambda x: x.sample(min(len(x), 50), random_state=1)).reset_index(drop=True)\n",
        "df_test2 = df_test.groupby('accent').apply(lambda x: x.sample(min(len(x), 50), random_state=1)).reset_index(drop=True)\n",
        "# remove accents with less than 300 samples\n",
        "df_train2 = df_train2.groupby('accent').filter(lambda x: len(x) >= 300)\n",
        "# get names of remaining accents\n",
        "remaining_accents = df_train2['accent'].unique()\n",
        "# filter dev and test sets to keep only the remaining accents\n",
        "df_dev2 = df_dev2[df_dev2['accent'].isin(remaining_accents)]\n",
        "df_test2 = df_test2[df_test2['accent'].isin(remaining_accents)]\n",
        "# reduce to 50 samples for dev and test sets\n",
        "\n",
        "# print stats of the new dataframe\n",
        "accent_counts2_train = df_train2['accent'].value_counts()\n",
        "accent_counts2_dev = df_dev2['accent'].value_counts()\n",
        "accent_counts2_test = df_test2['accent'].value_counts()\n",
        "# Print the result\n",
        "print(accent_counts2_train)\n",
        "print(accent_counts2_dev)\n",
        "print(accent_counts2_test)\n",
        "\n",
        "# save csv again with these samples\n",
        "os.makedirs('/content/accent-recog-slt2022/CommonAccent/data_small', exist_ok=True)\n",
        "df_train2.to_csv('/content/accent-recog-slt2022/CommonAccent/data_small/train.csv', index=False)\n",
        "df_dev2.to_csv('/content/accent-recog-slt2022/CommonAccent/data_small/dev.csv', index=False)\n",
        "df_test2.to_csv('/content/accent-recog-slt2022/CommonAccent/data_small/test.csv', index=False)\n",
        "# download files to disk\n",
        "!zip -r /content/accent-recog-slt2022/CommonAccent/data_small.zip /content/accent-recog-slt2022/CommonAccent/data_small\n",
        "# download\n",
        "from google.colab import files\n",
        "files.download(\"/content/accent-recog-slt2022/CommonAccent/data_small.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-PmRkAJCnmV",
        "outputId": "dd9d16e7-0c9d-4044-ba9c-7e05c7b4a731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accent\n",
            "TENDENTE AL SICULO MA NON MARCATO    1801\n",
            "BASILICATA TRENTINO                  1801\n",
            "VENETO                               1393\n",
            "MERIDIONALE                           134\n",
            "EMILIANO                               91\n",
            "Name: count, dtype: int64\n",
            "accent\n",
            "BASILICATA TRENTINO                  300\n",
            "TENDENTE AL SICULO MA NON MARCATO    300\n",
            "VENETO                               300\n",
            "Name: count, dtype: int64\n",
            "accent\n",
            "BASILICATA TRENTINO                  50\n",
            "TENDENTE AL SICULO MA NON MARCATO    50\n",
            "VENETO                               50\n",
            "Name: count, dtype: int64\n",
            "accent\n",
            "BASILICATA TRENTINO                  50\n",
            "TENDENTE AL SICULO MA NON MARCATO    50\n",
            "VENETO                               50\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-f3c15a7b6ddf>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_train2 = df_train.groupby('accent').apply(lambda x: x.sample(min(len(x), 300), random_state=1)).reset_index(drop=True)\n",
            "<ipython-input-20-f3c15a7b6ddf>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_dev2 = df_dev.groupby('accent').apply(lambda x: x.sample(min(len(x), 50), random_state=1)).reset_index(drop=True)\n",
            "<ipython-input-20-f3c15a7b6ddf>:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_test2 = df_test.groupby('accent').apply(lambda x: x.sample(min(len(x), 50), random_state=1)).reset_index(drop=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save audios locally (takes around 27min for italian)\n",
        "for item1 in cv_19_train:\n",
        "    # Check if the current file path is in the CSV file list\n",
        "    # print(item['path'])\n",
        "    # adjust the following line to your working directory\n",
        "    filename = (item1['path'].split('/')[-2] + '/' + item1['path'].split('/')[-1])\n",
        "    if filename in file_list_train or filename in file_list_test or filename in file_list_dev:\n",
        "      # Decode audio\n",
        "      audio_array = item1['audio']['array']  # Audio waveform\n",
        "      sampling_rate = item1['audio']['sampling_rate']  # Sampling rate\n",
        "\n",
        "      # Create the filename\n",
        "      file_name = os.path.join(save_dir, filename)\n",
        "      os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
        "\n",
        "      # Save the audio as a WAV file\n",
        "      write(file_name, sampling_rate, audio_array.astype(np.float32))  # Save as float32 for WAV compatibility\n"
      ],
      "metadata": {
        "id": "qYFe1THtuHEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takes 2 min for it dev, test\n",
        "for item1 in cv_19_dev:\n",
        "    filename = (item1['path'].split('/')[-2] + '/' + item1['path'].split('/')[-1])\n",
        "    if filename in file_list_train or filename in file_list_test or filename in file_list_dev:\n",
        "      # Decode audio\n",
        "      audio_array = item1['audio']['array']  # Audio waveform\n",
        "      sampling_rate = item1['audio']['sampling_rate']  # Sampling rate\n",
        "\n",
        "      # Create the filename\n",
        "      file_name = os.path.join(save_dir, filename)\n",
        "      os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
        "\n",
        "      # Save the audio as a WAV file\n",
        "      write(file_name, sampling_rate, audio_array.astype(np.float32))  # Save as float32 for WAV compatibility"
      ],
      "metadata": {
        "id": "VtBeEGDtYCRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item1 in cv_19_test:\n",
        "    filename = (item1['path'].split('/')[-2] + '/' + item1['path'].split('/')[-1])\n",
        "    if filename in file_list_train or filename in file_list_test or filename in file_list_dev:\n",
        "      # Decode audio\n",
        "      audio_array = item1['audio']['array']  # Audio waveform\n",
        "      sampling_rate = item1['audio']['sampling_rate']  # Sampling rate\n",
        "\n",
        "      # Create the filename\n",
        "      file_name = os.path.join(save_dir, filename)\n",
        "      os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
        "\n",
        "      # Save the audio as a WAV file\n",
        "      write(file_name, sampling_rate, audio_array.astype(np.float32))  # Save as float32 for WAV compatibility"
      ],
      "metadata": {
        "id": "ZfyNah9KYIYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After this step I would suggest to copy the .csv files and also the wav files to your gdrive so that you can load them from there next time.\n",
        "Next time (if you saved the wav files in your gdrive) you can copy it back to colab and can continue from there."
      ],
      "metadata": {
        "id": "-1n3cTWFZUVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p /content/accent-recog-slt2022/CommonAccent/data_small\n",
        "# !cp -R /content/drive/MyDrive/.../data/wav /content/accent-recog-slt2022/CommonAccent/data_small/wav_files"
      ],
      "metadata": {
        "id": "VGFp_4Bf_d_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R /content/accent-recog-slt2022/CommonAccent/data_small/wav_files /content/drive/MyDrive/.../data/wav"
      ],
      "metadata": {
        "id": "IF5PqPbiXsdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "# resample all files to 16khz\n",
        "base_dir = '/content/accent-recog-slt2022/CommonAccent/data_small/wav_files/wav_files/'\n",
        "\n",
        "# Walk through all subdirectories\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    for filename in files:\n",
        "        if filename.endswith('.mp3'):\n",
        "            audio_file = os.path.join(root, filename)\n",
        "            try:\n",
        "                # Load with librosa to ensure mono and 16kHz resampling\n",
        "                data, _ = librosa.load(audio_file, sr=16000, mono=True)\n",
        "                # Output path with .wav extension\n",
        "                new_path = audio_file.replace('.mp3', '.wav')\n",
        "                # Save as 16kHz mono .wav\n",
        "                sf.write(new_path, data, 16000)\n",
        "                # print(f\"Converted and saved: {new_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {audio_file}: {e}\")\n"
      ],
      "metadata": {
        "id": "2juSor7lxzis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies for training the model\n",
        "You should not get any errors here"
      ],
      "metadata": {
        "id": "fXxkRQoeD0bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas==2.2.2 \\\n",
        "    huggingface_hub>=0.7.0 \\\n",
        "    hyperpyyaml==0.0.1 \\\n",
        "    joblib \\\n",
        "    numpy==2.0.2 \\\n",
        "    packaging \\\n",
        "    pre-commit==2.3.0 \\\n",
        "    sentencepiece>=0.1.91 \\\n",
        "    SoundFile \\\n",
        "    tqdm"
      ],
      "metadata": {
        "id": "1oTznOs9vSkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga3ThIIw8q5K"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# You will probably have to adjust your audiopaths in the csv files:"
      ],
      "metadata": {
        "id": "p_NN_MHhEAyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/accent-recog-slt2022/CommonAccent/data_small/train.csv /content/accent-recog-slt2022/CommonAccent/data_small/train_orig.csv\n",
        "!cp /content/accent-recog-slt2022/CommonAccent/data_small/dev.csv /content/accent-recog-slt2022/CommonAccent/data_small/dev_orig.csv\n",
        "!cp /content/accent-recog-slt2022/CommonAccent/data_small/test.csv /content/accent-recog-slt2022/CommonAccent/data_small/test_orig.csv"
      ],
      "metadata": {
        "id": "GwlLLx15DxV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def update_csv_with_full_path_and_duration(\n",
        "    input_csv_path,\n",
        "    output_csv_path,\n",
        "    base_audio_path\n",
        "):\n",
        "    modified_rows = []\n",
        "\n",
        "    with open(input_csv_path, mode='r', newline='', encoding='utf-8') as infile:\n",
        "        reader = csv.DictReader(infile)\n",
        "\n",
        "        for row in reader:\n",
        "            try:\n",
        "                audio_path = os.path.join(base_audio_path, row['wav'].replace('.mp3', '.wav'))\n",
        "\n",
        "                data, sampling_rate = sf.read(audio_path)\n",
        "                duration = np.round(librosa.get_duration(y=data, sr=sampling_rate), 3)\n",
        "\n",
        "                row['duration'] = duration\n",
        "                row['wav'] = audio_path\n",
        "\n",
        "                modified_rows.append(row)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed processing {row['wav']}: {e}\")\n",
        "\n",
        "        fieldnames = reader.fieldnames\n",
        "\n",
        "    with open(output_csv_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
        "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(modified_rows)\n"
      ],
      "metadata": {
        "id": "PEaM7tT-NCRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_audio_path = '/content/accent-recog-slt2022/CommonAccent/data_small/wav_files/wav_files/'\n",
        "\n",
        "# Train\n",
        "update_csv_with_full_path_and_duration(\n",
        "    input_csv_path='/content/accent-recog-slt2022/CommonAccent/data_small/train_orig.csv',\n",
        "    output_csv_path='/content/accent-recog-slt2022/CommonAccent/data_small/train.csv',\n",
        "    base_audio_path=base_audio_path\n",
        ")\n",
        "\n",
        "# Dev\n",
        "update_csv_with_full_path_and_duration(\n",
        "    input_csv_path='/content/accent-recog-slt2022/CommonAccent/data_small/dev_orig.csv',\n",
        "    output_csv_path='/content/accent-recog-slt2022/CommonAccent/data_small/dev.csv',\n",
        "    base_audio_path=base_audio_path\n",
        ")\n",
        "\n",
        "# Test\n",
        "update_csv_with_full_path_and_duration(\n",
        "    input_csv_path='/content/accent-recog-slt2022/CommonAccent/data_small/test_orig.csv',\n",
        "    output_csv_path='/content/accent-recog-slt2022/CommonAccent/data_small/test.csv',\n",
        "    base_audio_path=base_audio_path\n",
        ")"
      ],
      "metadata": {
        "id": "NzNOJYwKNGWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/accent-recog-slt2022/CommonAccent\n",
        "# make .sh file executable:\n",
        "!chmod u+x run_accent_id_ecapa_tdnn.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS96svSH3Sti",
        "outputId": "5574daf0-8058-45b5-d46e-f3ef61be2d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/accent-recog-slt2022/CommonAccent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finally, we can run the model.\n",
        "You can try to run the training using cpu by adding\n",
        "\n",
        "--device=\"cpu\"\n",
        "\n",
        "to your .sh file (line 59)"
      ],
      "metadata": {
        "id": "3-LFB-nKEaHx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5Vz3bS0SBA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e29693cc-d8d1-4bbe-a307-ddbd6eb27c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** About to start the training ***\n",
            "*** output folder: results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986 ***\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986\n",
            "speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n",
            "speechbrain.pretrained.fetching - Fetch embedding_model.ckpt: Delegating to Huggingface hub, source speechbrain/spkrec-ecapa-voxceleb.\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: embedding_model\n",
            "speechbrain.core - Info: device arg overridden by command line input to: cuda:0\n",
            "speechbrain.core - 20.8M trainable parameters in AID\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "100% 29/29 [00:32<00:00,  1.13s/it, train_loss=7.51]\n",
            "100% 5/5 [00:02<00:00,  1.77it/s]\n",
            "speechbrain.utils.train_logger - Epoch: 1, lr: 1.00e-04 - train loss: 7.51 - valid loss: 4.81, valid error_rate: 2.67e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-41-42+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n",
            "100% 29/29 [00:31<00:00,  1.10s/it, train_loss=6.89]\n",
            "100% 5/5 [00:02<00:00,  2.48it/s]\n",
            "speechbrain.utils.train_logger - Epoch: 2, lr: 1.00e-04 - train loss: 6.89 - valid loss: 3.94, valid error_rate: 2.47e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-42-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-41-42+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n",
            "100% 29/29 [00:33<00:00,  1.15s/it, train_loss=6.41]\n",
            "100% 5/5 [00:02<00:00,  2.38it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.0001 to 9e-05\n",
            "speechbrain.utils.train_logger - Epoch: 3, lr: 1.00e-04 - train loss: 6.41 - valid loss: 3.44, valid error_rate: 3.00e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-42-52+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n",
            "100% 29/29 [00:34<00:00,  1.20s/it, train_loss=6.14]\n",
            "100% 5/5 [00:02<00:00,  1.95it/s]\n",
            "speechbrain.utils.train_logger - Epoch: 4, lr: 9.00e-05 - train loss: 6.14 - valid loss: 2.88, valid error_rate: 2.20e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-43-30+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-42-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-42-52+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n",
            "100% 29/29 [00:34<00:00,  1.18s/it, train_loss=5.85]\n",
            "100% 5/5 [00:02<00:00,  2.36it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 9e-05 to 8.1e-05\n",
            "speechbrain.utils.train_logger - Epoch: 5, lr: 9.00e-05 - train loss: 5.85 - valid loss: 3.23, valid error_rate: 3.00e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-44-07+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-43-30+00\n",
            "100% 5/5 [00:02<00:00,  1.97it/s]\n",
            "speechbrain.utils.train_logger - Epoch loaded: 4 - test loss: 2.82, test error_rate: 1.60e-01\n",
            "Done training of speechbrain/spkrec-ecapa-voxceleb/embedding_model.ckpt in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986\n"
          ]
        }
      ],
      "source": [
        "!./run_accent_id_ecapa_tdnn.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the correct pretrained_path: /content/accent-recog-slt2022/CommonAccent/results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/\n",
        "# and load_folder: !ref <pretrained_path>/CKPT+2025-05-15+09-43-30+00\n",
        "# in the yaml file!\n",
        "# if run is successful, it will create an analysis folder (in your results folder)\n",
        "!python accent_id/inference.py accent_id/hparams/inference_ecapa_tdnn.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoByyoA_Rsls",
        "outputId": "15d01ebb-0300-4419-c3ad-9bc9902edcad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/analysis\n",
            "speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n",
            "speechbrain.pretrained.fetching - Fetch embedding_model.ckpt: Using existing file/symlink in model_checkpoints/embedding_model.ckpt.\n",
            "speechbrain.pretrained.fetching - Fetch classifier.ckpt: Using existing file/symlink in model_checkpoints/classifier.ckpt.\n",
            "speechbrain.pretrained.fetching - Fetch accent_encoder.txt: Using existing file/symlink in model_checkpoints/label_encoder.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: embedding_model, classifier, label_encoder\n",
            "speechbrain.core - Info: device arg from hparam file is used\n",
            "speechbrain.core - 20.8M trainable parameters in AccID_inf\n",
            "100% 5/5 [00:02<00:00,  1.88it/s]\n",
            "100% 5/5 [00:02<00:00,  2.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our project starts here!\n",
        "\n",
        "We have chosen the following datasets:\n",
        "\n",
        "*   **Russian**:\n",
        "*   **Belarusian**: *Common Voice Delta Segment 14.0*\n",
        "Date: 28.6.2023\n",
        "Size:\t1,43GB\n",
        "Recorded Hours:\t74\n",
        "Validated Hours: 171\n",
        "License: CC-0\n",
        "Number of Voices:\t110\n",
        "Audio Format: \tMP3\n",
        "*   **Serbian**:\n"
      ],
      "metadata": {
        "id": "-p1-S2E2D-ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serbian"
      ],
      "metadata": {
        "id": "zHKM7Vx8IVXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Russian"
      ],
      "metadata": {
        "id": "JrXWxfxoFDU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Belarusian"
      ],
      "metadata": {
        "id": "bMcW-a2YFF_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #use this if you want to upload the file from colab"
      ],
      "metadata": {
        "id": "oZ19BTktL5Gm",
        "outputId": "0d289c64-13eb-40cf-b3d5-1f9df28688e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: if your file is in My Drive > Datasets\n",
        "gdrive_path = \"/content/drive/MyDrive/Colab Notebooks/cv-corpus-21.0-delta-2025-03-14-be.tar.gz\"\n",
        "extract_path = '/content/cv_data/be'\n",
        "\n",
        "import tarfile\n",
        "\n",
        "with tarfile.open(gdrive_path, \"r:gz\") as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "\n",
        "print(\"Extraction complete.\")"
      ],
      "metadata": {
        "id": "3RTQqKC7L9VW",
        "outputId": "7f84c43c-d580-4ea8-fa50-fc774d8c96b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "tar_path = \"/content/cv-corpus-21.0-delta-2025-03-14-be.tar.gz\" #your downloaded locally dataset\n",
        "extract_path = \"/content/cv_data/be\" #the foldr to store after. Change the iso to your languages thn\n",
        "\n",
        "with tarfile.open(tar_path, \"r:gz\") as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "\n",
        "print(\"Extraction complete.\")"
      ],
      "metadata": {
        "id": "ZThrQxQmJwQD",
        "outputId": "771bcc5a-5e37-4257-b49b-7955e629543a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "Compressed file ended before the end-of-stream marker was reached",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2294078414>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r:gz\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extraction complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, numeric_owner, filter)\u001b[0m\n\u001b[1;32m   2310\u001b[0m                 \u001b[0;31m# extracting contents can reset mtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m                 \u001b[0mdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfiltered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2312\u001b[0;31m             self._extract_one(tarinfo, path, set_attrs=not tarinfo.isdir(),\n\u001b[0m\u001b[1;32m   2313\u001b[0m                               \u001b[0mnumeric_owner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_owner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m                               filter_function=filter_function)\n",
            "\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36m_extract_one\u001b[0;34m(self, tarinfo, path, set_attrs, numeric_owner, filter_function)\u001b[0m\n\u001b[1;32m   2413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2415\u001b[0;31m             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n\u001b[0m\u001b[1;32m   2416\u001b[0m                                  \u001b[0mset_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m                                  \u001b[0mnumeric_owner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_owner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, tarinfo, targetpath, set_attrs, numeric_owner, filter_function, extraction_root)\u001b[0m\n\u001b[1;32m   2502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2504\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2505\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36mmakefile\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2559\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2561\u001b[0;31m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmakeunknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 raise EOFError(\"Compressed file ended before the \"\n\u001b[0m\u001b[1;32m    519\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "def prepare_common_accent(\n",
        "        data_folder,\n",
        "        save_folder,\n",
        "        accented_letters=False,\n",
        "        language=\"en\",        \n",
        "        skip_prep=False,\n",
        "    ):\n",
        "\n",
        "    \"\"\"\n",
        "    Prepares the csv files for the CommonAccent dataset for Accent Classification.\n",
        "    Download: https://commonvoice.mozilla.org/en/datasets\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    data_folder : str\n",
        "        Path to the folder where the CommonAccent dataset for Accent Classification is stored.\n",
        "        This path should include the multi: /datasets/CommonAccent\n",
        "    save_folder : str\n",
        "        The directory where to store the csv files.\n",
        "    max_duration : int, optional\n",
        "        Max duration (in seconds) of training uterances.\n",
        "    accented_letters : bool, optional\n",
        "        Defines if accented letters will be kept as individual letters or\n",
        "        transformed to the closest non-accented letters.\n",
        "    language: str\n",
        "        Specify the language for text normalization.        \n",
        "    skip_prep: bool\n",
        "        If True, skip data preparation.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> from recipes.CommonAccent.common_accent_prepare import prepare_common_accent\n",
        "    >>> data_folder = '/datasets/CommonAccent'\n",
        "    >>> save_folder = 'exp/CommonAccent_exp'\n",
        "    >>> prepare_common_accent(\\\n",
        "            data_folder,\\\n",
        "            save_folder,\\\n",
        "            skip_prep=False\\\n",
        "        )\n",
        "    \"\"\"\n",
        "```\n"
      ],
      "metadata": {
        "id": "4IY89c7CIqIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python common_accent_prepare.py --language \"be\" /content/cv_data/be /content/common_accent_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d41c1aa-c205-4e60-f1ce-aab0aec6a935",
        "id": "JKmClhZBFNvL"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/common_accent_prepare.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "from datasets import load_dataset\n",
        "\n",
        "data_path = \"/content/accent-recog-slt2022/CommonAccent/data/\"\n",
        "# Load CSV\n",
        "csv_path_train = data_path + \"train.csv\"\n",
        "df_train = pd.read_csv(csv_path_train)\n",
        "file_list_train = list(set(df_train['wav']))\n",
        "\n",
        "csv_path_test = data_path + \"test.csv\"\n",
        "df_test = pd.read_csv(csv_path_test)\n",
        "file_list_test = list(set(df_test['wav']))\n",
        "\n",
        "csv_path_dev = data_path + \"dev.csv\"\n",
        "df_dev = pd.read_csv(csv_path_dev)\n",
        "file_list_dev = list(set(df_dev['wav']))\n",
        "\n",
        "# Set save directory\n",
        "save_dir = data_path + \"wav_files\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Load dataset in streaming mode\n",
        "language = \"be\"  # or whatever language code you're using\n",
        "cv_14_be_train = load_dataset(\"fsicoli/common_voice_19_0\", language, streaming=True, split=\"train\", trust_remote_code=True)\n",
        "print(next(iter(cv_14_be_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad6a31e-3f22-402f-fd92-e8410005b469",
        "id": "J9dhLrqeFNvM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Reading metadata...: 171388it [00:07, 23662.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'client_id': 'c14f21cacf2b7701ad0bead0dd1b31ec9d3a1557708e446de55e98b4b470cf31072c82543e5ba518c5c187a91868878a4e32727054a3dd94f9df41c9a13d8c62', 'path': 'it_train_0/common_voice_it_17415777.mp3', 'audio': {'path': 'it_train_0/common_voice_it_17415777.mp3', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
            "       -1.61342832e-05, -1.57291943e-05, -1.16234423e-05]), 'sampling_rate': 48000}, 'sentence': \"Il marchese aveva già moglie in quell'epoca?\", 'up_votes': 3, 'down_votes': 0, 'age': '', 'gender': '', 'accent': '', 'locale': 'it', 'segment': '', 'variant': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_19_dev = load_dataset(\"fsicoli/common_voice_19_0\", language, streaming=False, split=\"validation\", trust_remote_code=True)\n",
        "cv_19_test = load_dataset(\"fsicoli/common_voice_19_0\", language, streaming=False, split=\"test\", trust_remote_code=True)\n"
      ],
      "metadata": {
        "id": "4Z2evoZ9FNvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Count entries per accent\n",
        "accent_counts = df_train['accent'].value_counts()\n",
        "\n",
        "# Print the result\n",
        "print(accent_counts)\n",
        "\n",
        "# select randomly max 300 samples for each accent that has more than 300 samples\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003c3702-9ce5-40c1-8950-9693771089f4",
        "id": "myZLU5jiFNvM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accent\n",
            "TENDENTE AL SICULO MA NON MARCATO    1801\n",
            "BASILICATA TRENTINO                  1801\n",
            "VENETO                               1393\n",
            "MERIDIONALE                           134\n",
            "EMILIANO                               91\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation with confusion matrix, error rate, precision, and F1-\n",
        "score"
      ],
      "metadata": {
        "id": "ED59kUemC3jW"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}