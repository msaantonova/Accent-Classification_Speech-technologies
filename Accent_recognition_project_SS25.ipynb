{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msaantonova/Accent-Classification_Speech-technologies/blob/main/Accent_recognition_project_SS25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "utPRj8QSfBW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repository from the paper\n",
        "\n",
        "\"This repository provides all the necessary tools to perform accent identification from speech recordings with SpeechBrain toolkit! The system uses a model fine-tuned on the CommonAccent dataset in English (21 accents). The provided system can recognize the following 21 accents of English from short speech recordings\""
      ],
      "metadata": {
        "id": "6uOohfJNCNLx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvKoxtf7-l7s",
        "outputId": "cad29cfe-4b3c-478c-bc0b-dd5680e766c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'accent-recog-slt2022'...\n",
            "remote: Enumerating objects: 527, done.\u001b[K\n",
            "remote: Counting objects: 100% (204/204), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 527 (delta 182), reused 155 (delta 154), pack-reused 323 (from 1)\u001b[K\n",
            "Receiving objects: 100% (527/527), 2.64 MiB | 5.73 MiB/s, done.\n",
            "Resolving deltas: 100% (342/342), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lgspeech/accent-recog-slt2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAG2EUzBeABn",
        "outputId": "40cf4722-250b-4448-a76f-a24a74556242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/accent-recog-slt2022\n",
            "Ignoring SoundFile: markers 'sys_platform == \"win32\"' don't match your environment\n",
            "Collecting speechbrain==0.5.13 (from -r requirements.txt (line 1))\n",
            "  Downloading speechbrain-0.5.13-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting datasets==2.8.0 (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting transformers==4.25.1 (from -r requirements.txt (line 3))\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting librosa==0.9.2 (from -r requirements.txt (line 4))\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting ipdb>=0.13.9 (from -r requirements.txt (line 5))\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.33.0)\n",
            "Collecting hyperpyyaml>=0.0.1 (from -r requirements.txt (line 8))\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (24.2)\n",
            "Collecting pre-commit>=2.3.0 (from -r requirements.txt (line 12))\n",
            "  Downloading pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting scipy<1.9,>=1.4.1 (from -r requirements.txt (line 13))\n",
            "  Downloading scipy-1.6.1.tar.gz (27.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.6.0+cu124)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchaudio<=0.11.0,>=0.9.0 (from versions: 2.0.1, 2.0.2, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchaudio<=0.11.0,>=0.9.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%cd /content/accent-recog-slt2022\n",
        "!python -m pip install -r requirements.txt\n",
        "# you can ignore any errors for now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iQrLs6ilfGon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d18aea-f900-40c4-d0d7-0dcbf2a614fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/474.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m471.0/474.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/177.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.6.1 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets==3.0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change working directory:\n",
        "%cd CommonAccent/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m6-V5CHYS-V",
        "outputId": "9c48c08b-0550-41db-821b-0a7dc886a500"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/accent-recog-slt2022/CommonAccent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the data (or stream) and create the list of filtered items\n",
        "\n",
        "You can either use streaming, or save the files locally. you can check at common voice, how big the corpus for each language is.\n",
        "If you use streaming, it  will take a few hours.\n",
        "\n",
        "The aim of it is to create lists of all audios that have marked accent in the metadata, so you can choose which ones of these you want for classification."
      ],
      "metadata": {
        "id": "gAQzxiFMYUnj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAt-X0eXezdf",
        "outputId": "692d63c8-5371-43ff-841e-c3dee49fc101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/download_data_hf.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#this part descrbes the dataset index and the language\n",
        "!python download_data_hf.py --language \"it\" data/cv_11/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the filtered list to be used in this model --> create csv files in correct form"
      ],
      "metadata": {
        "id": "xDqntrpPYjUn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Zgu6_R0J6dP_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "265510a5-72a1-455e-cfbd-946825821583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.0/499.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.5/363.4 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3796896608>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -q speechbrain==0.5.13      transformers==4.25.1      librosa==0.9.2      ipdb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     return {\n\u001b[1;32m   1086\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\".py\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     }\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    605\u001b[0m             make_files(\n\u001b[1;32m    606\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/importlib_metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \"\"\"\n\u001b[1;32m   1234\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \"\"\"\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m__fspath__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             self._str = self._format_parsed_parts(self._drv, self._root,\n\u001b[0m\u001b[1;32m    543\u001b[0m                                                   self._parts) or '.'\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_format_parsed_parts\u001b[0;34m(cls, drv, root, parts)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_parsed_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdrv\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install -q speechbrain==0.5.13 \\\n",
        "    transformers==4.25.1 \\\n",
        "    librosa==0.9.2 \\\n",
        "    ipdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python common_accent_prepare.py --language \"it\" data/cv_11 data/"
      ],
      "metadata": {
        "id": "TJ25UXrSYQpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "from datasets import load_dataset\n",
        "\n",
        "data_path = \"/content/accent-recog-slt2022/CommonAccent/data/\"\n",
        "# Load CSV\n",
        "csv_path_train = data_path + \"train.csv\"\n",
        "df_train = pd.read_csv(csv_path_train)\n",
        "file_list_train = list(set(df_train['wav']))\n",
        "\n",
        "csv_path_test = data_path + \"test.csv\"\n",
        "df_test = pd.read_csv(csv_path_test)\n",
        "file_list_test = list(set(df_test['wav']))\n",
        "\n",
        "csv_path_dev = data_path + \"dev.csv\"\n",
        "df_dev = pd.read_csv(csv_path_dev)\n",
        "file_list_dev = list(set(df_dev['wav']))\n",
        "\n",
        "# Set save directory\n",
        "save_dir = data_path + \"wav_files\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Load dataset in streaming mode\n",
        "language = \"it\"  # or whatever language code you're using\n",
        "cv_19_train = load_dataset(\"fsicoli/common_voice_19_0\", language, streaming=True, split=\"train\", trust_remote_code=True)\n",
        "print(next(iter(cv_19_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pHghJSvEuEq",
        "outputId": "6ad6a31e-3f22-402f-fd92-e8410005b469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Reading metadata...: 171388it [00:07, 23662.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'client_id': 'c14f21cacf2b7701ad0bead0dd1b31ec9d3a1557708e446de55e98b4b470cf31072c82543e5ba518c5c187a91868878a4e32727054a3dd94f9df41c9a13d8c62', 'path': 'it_train_0/common_voice_it_17415777.mp3', 'audio': {'path': 'it_train_0/common_voice_it_17415777.mp3', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
            "       -1.61342832e-05, -1.57291943e-05, -1.16234423e-05]), 'sampling_rate': 48000}, 'sentence': \"Il marchese aveva già moglie in quell'epoca?\", 'up_votes': 3, 'down_votes': 0, 'age': '', 'gender': '', 'accent': '', 'locale': 'it', 'segment': '', 'variant': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_19_dev = load_dataset(\"fsicoli/common_voice_19_0\", language, streaming=False, split=\"validation\", trust_remote_code=True)\n",
        "cv_19_test = load_dataset(\"fsicoli/common_voice_19_0\", language, streaming=False, split=\"test\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "PMZFhNN_V2Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Count entries per accent\n",
        "accent_counts = df_train['accent'].value_counts()\n",
        "\n",
        "# Print the result\n",
        "print(accent_counts)\n",
        "\n",
        "# select randomly max 300 samples for each accent that has more than 300 samples\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Uyu3fx-SAlo",
        "outputId": "003c3702-9ce5-40c1-8950-9693771089f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accent\n",
            "TENDENTE AL SICULO MA NON MARCATO    1801\n",
            "BASILICATA TRENTINO                  1801\n",
            "VENETO                               1393\n",
            "MERIDIONALE                           134\n",
            "EMILIANO                               91\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code adjusts the audio paths and can be used for balancing the data:"
      ],
      "metadata": {
        "id": "1bk_7sQqCp-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# add /content/accent-recog-slt2022/CommonAccent/data_small to each \"wav\" in the csv .../train.csv\n",
        "save_dir_colab = data_path\n",
        "# \"content/accent-recog-slt2022/CommonAccent/data_small/\"\n",
        "df_train['wav'] = df_train['wav'].apply(lambda x: os.path.join(save_dir_colab, x))\n",
        "df_test['wav'] = df_test['wav'].apply(lambda x: os.path.join(save_dir_colab, x))\n",
        "df_dev['wav'] = df_dev['wav'].apply(lambda x: os.path.join(save_dir_colab, x))\n",
        "df_train.to_csv(csv_path_train, index=False)\n",
        "\n",
        "# show all available accents\n",
        "accent_counts = df_train['accent'].value_counts()\n",
        "\n",
        "# Print the result\n",
        "print(accent_counts)\n",
        "\n",
        "# select randomly max 300 samples for each accent\n",
        "df_train2 = df_train.groupby('accent').apply(lambda x: x.sample(min(len(x), 300), random_state=1)).reset_index(drop=True)\n",
        "df_dev2 = df_dev.groupby('accent').apply(lambda x: x.sample(min(len(x), 50), random_state=1)).reset_index(drop=True)\n",
        "df_test2 = df_test.groupby('accent').apply(lambda x: x.sample(min(len(x), 50), random_state=1)).reset_index(drop=True)\n",
        "# remove accents with less than 300 samples\n",
        "df_train2 = df_train2.groupby('accent').filter(lambda x: len(x) >= 300)\n",
        "# get names of remaining accents\n",
        "remaining_accents = df_train2['accent'].unique()\n",
        "# filter dev and test sets to keep only the remaining accents\n",
        "df_dev2 = df_dev2[df_dev2['accent'].isin(remaining_accents)]\n",
        "df_test2 = df_test2[df_test2['accent'].isin(remaining_accents)]\n",
        "# reduce to 50 samples for dev and test sets\n",
        "\n",
        "# print stats of the new dataframe\n",
        "accent_counts2_train = df_train2['accent'].value_counts()\n",
        "accent_counts2_dev = df_dev2['accent'].value_counts()\n",
        "accent_counts2_test = df_test2['accent'].value_counts()\n",
        "# Print the result\n",
        "print(accent_counts2_train)\n",
        "print(accent_counts2_dev)\n",
        "print(accent_counts2_test)\n",
        "\n",
        "# save csv again with these samples\n",
        "os.makedirs('/content/accent-recog-slt2022/CommonAccent/data_small', exist_ok=True)\n",
        "df_train2.to_csv('/content/accent-recog-slt2022/CommonAccent/data_small/train.csv', index=False)\n",
        "df_dev2.to_csv('/content/accent-recog-slt2022/CommonAccent/data_small/dev.csv', index=False)\n",
        "df_test2.to_csv('/content/accent-recog-slt2022/CommonAccent/data_small/test.csv', index=False)\n",
        "# download files to disk\n",
        "!zip -r /content/accent-recog-slt2022/CommonAccent/data_small.zip /content/accent-recog-slt2022/CommonAccent/data_small\n",
        "# download\n",
        "from google.colab import files\n",
        "files.download(\"/content/accent-recog-slt2022/CommonAccent/data_small.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-PmRkAJCnmV",
        "outputId": "dd9d16e7-0c9d-4044-ba9c-7e05c7b4a731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accent\n",
            "TENDENTE AL SICULO MA NON MARCATO    1801\n",
            "BASILICATA TRENTINO                  1801\n",
            "VENETO                               1393\n",
            "MERIDIONALE                           134\n",
            "EMILIANO                               91\n",
            "Name: count, dtype: int64\n",
            "accent\n",
            "BASILICATA TRENTINO                  300\n",
            "TENDENTE AL SICULO MA NON MARCATO    300\n",
            "VENETO                               300\n",
            "Name: count, dtype: int64\n",
            "accent\n",
            "BASILICATA TRENTINO                  50\n",
            "TENDENTE AL SICULO MA NON MARCATO    50\n",
            "VENETO                               50\n",
            "Name: count, dtype: int64\n",
            "accent\n",
            "BASILICATA TRENTINO                  50\n",
            "TENDENTE AL SICULO MA NON MARCATO    50\n",
            "VENETO                               50\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-f3c15a7b6ddf>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_train2 = df_train.groupby('accent').apply(lambda x: x.sample(min(len(x), 300), random_state=1)).reset_index(drop=True)\n",
            "<ipython-input-20-f3c15a7b6ddf>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_dev2 = df_dev.groupby('accent').apply(lambda x: x.sample(min(len(x), 50), random_state=1)).reset_index(drop=True)\n",
            "<ipython-input-20-f3c15a7b6ddf>:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_test2 = df_test.groupby('accent').apply(lambda x: x.sample(min(len(x), 50), random_state=1)).reset_index(drop=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save audios locally (takes around 27min for italian)\n",
        "for item1 in cv_19_train:\n",
        "    # Check if the current file path is in the CSV file list\n",
        "    # print(item['path'])\n",
        "    # adjust the following line to your working directory\n",
        "    filename = (item1['path'].split('/')[-2] + '/' + item1['path'].split('/')[-1])\n",
        "    if filename in file_list_train or filename in file_list_test or filename in file_list_dev:\n",
        "      # Decode audio\n",
        "      audio_array = item1['audio']['array']  # Audio waveform\n",
        "      sampling_rate = item1['audio']['sampling_rate']  # Sampling rate\n",
        "\n",
        "      # Create the filename\n",
        "      file_name = os.path.join(save_dir, filename)\n",
        "      os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
        "\n",
        "      # Save the audio as a WAV file\n",
        "      write(file_name, sampling_rate, audio_array.astype(np.float32))  # Save as float32 for WAV compatibility\n"
      ],
      "metadata": {
        "id": "qYFe1THtuHEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takes 2 min for it dev, test\n",
        "for item1 in cv_19_dev:\n",
        "    filename = (item1['path'].split('/')[-2] + '/' + item1['path'].split('/')[-1])\n",
        "    if filename in file_list_train or filename in file_list_test or filename in file_list_dev:\n",
        "      # Decode audio\n",
        "      audio_array = item1['audio']['array']  # Audio waveform\n",
        "      sampling_rate = item1['audio']['sampling_rate']  # Sampling rate\n",
        "\n",
        "      # Create the filename\n",
        "      file_name = os.path.join(save_dir, filename)\n",
        "      os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
        "\n",
        "      # Save the audio as a WAV file\n",
        "      write(file_name, sampling_rate, audio_array.astype(np.float32))  # Save as float32 for WAV compatibility"
      ],
      "metadata": {
        "id": "VtBeEGDtYCRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item1 in cv_19_test:\n",
        "    filename = (item1['path'].split('/')[-2] + '/' + item1['path'].split('/')[-1])\n",
        "    if filename in file_list_train or filename in file_list_test or filename in file_list_dev:\n",
        "      # Decode audio\n",
        "      audio_array = item1['audio']['array']  # Audio waveform\n",
        "      sampling_rate = item1['audio']['sampling_rate']  # Sampling rate\n",
        "\n",
        "      # Create the filename\n",
        "      file_name = os.path.join(save_dir, filename)\n",
        "      os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
        "\n",
        "      # Save the audio as a WAV file\n",
        "      write(file_name, sampling_rate, audio_array.astype(np.float32))  # Save as float32 for WAV compatibility"
      ],
      "metadata": {
        "id": "ZfyNah9KYIYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After this step I would suggest to copy the .csv files and also the wav files to your gdrive so that you can load them from there next time.\n",
        "Next time (if you saved the wav files in your gdrive) you can copy it back to colab and can continue from there."
      ],
      "metadata": {
        "id": "-1n3cTWFZUVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p /content/accent-recog-slt2022/CommonAccent/data_small\n",
        "# !cp -R /content/drive/MyDrive/.../data/wav /content/accent-recog-slt2022/CommonAccent/data_small/wav_files"
      ],
      "metadata": {
        "id": "VGFp_4Bf_d_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R /content/accent-recog-slt2022/CommonAccent/data_small/wav_files /content/drive/MyDrive/.../data/wav"
      ],
      "metadata": {
        "id": "IF5PqPbiXsdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "# resample all files to 16khz\n",
        "base_dir = '/content/accent-recog-slt2022/CommonAccent/data_small/wav_files/wav_files/'\n",
        "\n",
        "# Walk through all subdirectories\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    for filename in files:\n",
        "        if filename.endswith('.mp3'):\n",
        "            audio_file = os.path.join(root, filename)\n",
        "            try:\n",
        "                # Load with librosa to ensure mono and 16kHz resampling\n",
        "                data, _ = librosa.load(audio_file, sr=16000, mono=True)\n",
        "                # Output path with .wav extension\n",
        "                new_path = audio_file.replace('.mp3', '.wav')\n",
        "                # Save as 16kHz mono .wav\n",
        "                sf.write(new_path, data, 16000)\n",
        "                # print(f\"Converted and saved: {new_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {audio_file}: {e}\")\n"
      ],
      "metadata": {
        "id": "2juSor7lxzis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies for training the model\n",
        "You should not get any errors here"
      ],
      "metadata": {
        "id": "fXxkRQoeD0bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas==2.2.2 \\\n",
        "    huggingface_hub>=0.7.0 \\\n",
        "    hyperpyyaml==0.0.1 \\\n",
        "    joblib \\\n",
        "    numpy==2.0.2 \\\n",
        "    packaging \\\n",
        "    pre-commit==2.3.0 \\\n",
        "    sentencepiece>=0.1.91 \\\n",
        "    SoundFile \\\n",
        "    tqdm"
      ],
      "metadata": {
        "id": "1oTznOs9vSkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga3ThIIw8q5K"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# You will probably have to adjust your audiopaths in the csv files:"
      ],
      "metadata": {
        "id": "p_NN_MHhEAyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/accent-recog-slt2022/CommonAccent/data_small/train.csv /content/accent-recog-slt2022/CommonAccent/data_small/train_orig.csv\n",
        "!cp /content/accent-recog-slt2022/CommonAccent/data_small/dev.csv /content/accent-recog-slt2022/CommonAccent/data_small/dev_orig.csv\n",
        "!cp /content/accent-recog-slt2022/CommonAccent/data_small/test.csv /content/accent-recog-slt2022/CommonAccent/data_small/test_orig.csv"
      ],
      "metadata": {
        "id": "GwlLLx15DxV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def update_csv_with_full_path_and_duration(\n",
        "    input_csv_path,\n",
        "    output_csv_path,\n",
        "    base_audio_path\n",
        "):\n",
        "    modified_rows = []\n",
        "\n",
        "    with open(input_csv_path, mode='r', newline='', encoding='utf-8') as infile:\n",
        "        reader = csv.DictReader(infile)\n",
        "\n",
        "        for row in reader:\n",
        "            try:\n",
        "                audio_path = os.path.join(base_audio_path, row['wav'].replace('.mp3', '.wav'))\n",
        "\n",
        "                data, sampling_rate = sf.read(audio_path)\n",
        "                duration = np.round(librosa.get_duration(y=data, sr=sampling_rate), 3)\n",
        "\n",
        "                row['duration'] = duration\n",
        "                row['wav'] = audio_path\n",
        "\n",
        "                modified_rows.append(row)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed processing {row['wav']}: {e}\")\n",
        "\n",
        "        fieldnames = reader.fieldnames\n",
        "\n",
        "    with open(output_csv_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
        "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(modified_rows)\n"
      ],
      "metadata": {
        "id": "PEaM7tT-NCRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_audio_path = '/content/accent-recog-slt2022/CommonAccent/data_small/wav_files/wav_files/'\n",
        "\n",
        "# Train\n",
        "update_csv_with_full_path_and_duration(\n",
        "    input_csv_path='/content/accent-recog-slt2022/CommonAccent/data_small/train_orig.csv',\n",
        "    output_csv_path='/content/accent-recog-slt2022/CommonAccent/data_small/train.csv',\n",
        "    base_audio_path=base_audio_path\n",
        ")\n",
        "\n",
        "# Dev\n",
        "update_csv_with_full_path_and_duration(\n",
        "    input_csv_path='/content/accent-recog-slt2022/CommonAccent/data_small/dev_orig.csv',\n",
        "    output_csv_path='/content/accent-recog-slt2022/CommonAccent/data_small/dev.csv',\n",
        "    base_audio_path=base_audio_path\n",
        ")\n",
        "\n",
        "# Test\n",
        "update_csv_with_full_path_and_duration(\n",
        "    input_csv_path='/content/accent-recog-slt2022/CommonAccent/data_small/test_orig.csv',\n",
        "    output_csv_path='/content/accent-recog-slt2022/CommonAccent/data_small/test.csv',\n",
        "    base_audio_path=base_audio_path\n",
        ")"
      ],
      "metadata": {
        "id": "NzNOJYwKNGWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/accent-recog-slt2022/CommonAccent\n",
        "# make .sh file executable:\n",
        "!chmod u+x run_accent_id_ecapa_tdnn.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS96svSH3Sti",
        "outputId": "5574daf0-8058-45b5-d46e-f3ef61be2d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/accent-recog-slt2022/CommonAccent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finally, we can run the model.\n",
        "You can try to run the training using cpu by adding\n",
        "\n",
        "--device=\"cpu\"\n",
        "\n",
        "to your .sh file (line 59)"
      ],
      "metadata": {
        "id": "3-LFB-nKEaHx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5Vz3bS0SBA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e29693cc-d8d1-4bbe-a307-ddbd6eb27c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** About to start the training ***\n",
            "*** output folder: results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986 ***\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986\n",
            "speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n",
            "speechbrain.pretrained.fetching - Fetch embedding_model.ckpt: Delegating to Huggingface hub, source speechbrain/spkrec-ecapa-voxceleb.\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: embedding_model\n",
            "speechbrain.core - Info: device arg overridden by command line input to: cuda:0\n",
            "speechbrain.core - 20.8M trainable parameters in AID\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "100% 29/29 [00:32<00:00,  1.13s/it, train_loss=7.51]\n",
            "100% 5/5 [00:02<00:00,  1.77it/s]\n",
            "speechbrain.utils.train_logger - Epoch: 1, lr: 1.00e-04 - train loss: 7.51 - valid loss: 4.81, valid error_rate: 2.67e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-41-42+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n",
            "100% 29/29 [00:31<00:00,  1.10s/it, train_loss=6.89]\n",
            "100% 5/5 [00:02<00:00,  2.48it/s]\n",
            "speechbrain.utils.train_logger - Epoch: 2, lr: 1.00e-04 - train loss: 6.89 - valid loss: 3.94, valid error_rate: 2.47e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-42-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-41-42+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n",
            "100% 29/29 [00:33<00:00,  1.15s/it, train_loss=6.41]\n",
            "100% 5/5 [00:02<00:00,  2.38it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.0001 to 9e-05\n",
            "speechbrain.utils.train_logger - Epoch: 3, lr: 1.00e-04 - train loss: 6.41 - valid loss: 3.44, valid error_rate: 3.00e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-42-52+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n",
            "100% 29/29 [00:34<00:00,  1.20s/it, train_loss=6.14]\n",
            "100% 5/5 [00:02<00:00,  1.95it/s]\n",
            "speechbrain.utils.train_logger - Epoch: 4, lr: 9.00e-05 - train loss: 6.14 - valid loss: 2.88, valid error_rate: 2.20e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-43-30+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-42-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-42-52+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n",
            "100% 29/29 [00:34<00:00,  1.18s/it, train_loss=5.85]\n",
            "100% 5/5 [00:02<00:00,  2.36it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 9e-05 to 8.1e-05\n",
            "speechbrain.utils.train_logger - Epoch: 5, lr: 9.00e-05 - train loss: 5.85 - valid loss: 3.23, valid error_rate: 3.00e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-44-07+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/CKPT+2025-05-15+09-43-30+00\n",
            "100% 5/5 [00:02<00:00,  1.97it/s]\n",
            "speechbrain.utils.train_logger - Epoch loaded: 4 - test loss: 2.82, test error_rate: 1.60e-01\n",
            "Done training of speechbrain/spkrec-ecapa-voxceleb/embedding_model.ckpt in results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986\n"
          ]
        }
      ],
      "source": [
        "!./run_accent_id_ecapa_tdnn.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the correct pretrained_path: /content/accent-recog-slt2022/CommonAccent/results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/\n",
        "# and load_folder: !ref <pretrained_path>/CKPT+2025-05-15+09-43-30+00\n",
        "# in the yaml file!\n",
        "# if run is successful, it will create an analysis folder (in your results folder)\n",
        "!python accent_id/inference.py accent_id/hparams/inference_ecapa_tdnn.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoByyoA_Rsls",
        "outputId": "15d01ebb-0300-4419-c3ad-9bc9902edcad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/analysis\n",
            "speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n",
            "speechbrain.pretrained.fetching - Fetch embedding_model.ckpt: Using existing file/symlink in model_checkpoints/embedding_model.ckpt.\n",
            "speechbrain.pretrained.fetching - Fetch classifier.ckpt: Using existing file/symlink in model_checkpoints/classifier.ckpt.\n",
            "speechbrain.pretrained.fetching - Fetch accent_encoder.txt: Using existing file/symlink in model_checkpoints/label_encoder.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: embedding_model, classifier, label_encoder\n",
            "speechbrain.core - Info: device arg from hparam file is used\n",
            "speechbrain.core - 20.8M trainable parameters in AccID_inf\n",
            "100% 5/5 [00:02<00:00,  1.88it/s]\n",
            "100% 5/5 [00:02<00:00,  2.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our project starts here!\n",
        "\n",
        "for 3 languages:\n",
        "*   **Russian**\n",
        "*   **Belarusian**\n",
        "*   **Serbian**"
      ],
      "metadata": {
        "id": "-p1-S2E2D-ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serbian"
      ],
      "metadata": {
        "id": "zHKM7Vx8IVXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Russian"
      ],
      "metadata": {
        "id": "JrXWxfxoFDU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwM4R0DfLEf-",
        "outputId": "db56fef9-6be2-4018-b48b-99324b8e6856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "tar_path = \"/content/cv-corpus-21.0-delta-2025-03-14-ru.tar\" #your downloaded locally dataset\n",
        "extract_path = \"/content/cv_data\"\n",
        "\n",
        "with tarfile.open(tar_path, \"r\") as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "\n",
        "print(\"Extraction complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbxykxcPRnuH",
        "outputId": "c0c37fdd-4e20-4133-e6fd-362526955a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q speechbrain==0.5.13 \\\n",
        "    transformers==4.25.1 \\\n",
        "    librosa==0.9.2 \\\n",
        "    ipdb"
      ],
      "metadata": {
        "id": "1GaYRSeBS8Hv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb174496-6567-48a9-fc39-935e837dd694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.0/499.0 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "data_path = \"/content/cv_data/cv-corpus-21.0-delta-2025-03-14/ru\"\n",
        "\n",
        "validated = pd.read_csv(os.path.join(data_path, \"validated.tsv\"), sep='\\t')\n",
        "other = pd.read_csv(os.path.join(data_path, \"other.tsv\"), sep='\\t')\n",
        "\n",
        "print(f\"Validated samples: {len(validated)}\")\n",
        "print(f\"Other samples: {len(other)}\")\n",
        "\n",
        "df_full = pd.concat([validated, other], ignore_index=True)\n",
        "\n",
        "print(f\"Total samples combined: {len(df_full)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd_hd-3VYKiC",
        "outputId": "ecbeb780-63a4-4f24-f9aa-b5d956826159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validated samples: 90\n",
            "Other samples: 2940\n",
            "Total samples combined: 3030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "data_path = \"/content/cv_data/cv-corpus-21.0-delta-2025-03-14/ru\"\n",
        "validated_path = os.path.join(data_path, \"validated.tsv\")\n",
        "other_path = os.path.join(data_path, \"other.tsv\")\n",
        "\n",
        "df_validated = pd.read_csv(validated_path, sep='\\t')\n",
        "df_other = pd.read_csv(other_path, sep='\\t')\n",
        "\n",
        "df_validated['source'] = 'validated'\n",
        "df_other['source'] = 'other'\n",
        "\n",
        "df_combined = pd.concat([df_validated, df_other], ignore_index=True)\n",
        "\n",
        "print(f\"Validated samples: {len(df_validated)}\")\n",
        "print(f\"Other samples: {len(df_other)}\")\n",
        "print(f\"Total samples combined: {len(df_combined)}\")\n",
        "\n",
        "# 70% train, 15% dev, 15% test\n",
        "df_train_ru, df_temp_ru = train_test_split(df_combined, test_size=0.3, random_state=42)\n",
        "df_dev_ru, df_test_ru = train_test_split(df_temp_ru, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Train size russian: {len(df_train_ru)}\")\n",
        "print(f\"Dev size russian: {len(df_dev_ru)}\")\n",
        "print(f\"Test size russian: {len(df_test_ru)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAB8p6cggAhr",
        "outputId": "e39c646d-3354-4dfa-c39e-748ce49a0e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validated samples: 90\n",
            "Other samples: 2940\n",
            "Total samples combined: 3030\n",
            "Train size russian: 2121\n",
            "Dev size russian: 454\n",
            "Test size russian: 455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_ru.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "pN5Y6BPKeXNL",
        "outputId": "892616f8-1e32-47a8-9cd9-34f7805f81e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              client_id  \\\n",
              "2546  d3f1f7c923f0522c03e865129fff2650df0b66ec0df81b...   \n",
              "279   4a3d198ccac94aa3330809ce2eef552dec6625d1169508...   \n",
              "1510  860c378a00fee36eb354361dae39730bfa969c53e99baf...   \n",
              "1553  860c378a00fee36eb354361dae39730bfa969c53e99baf...   \n",
              "2230  e4571c8ae7d79a96e6f28a3facacdd14a240bd3f246456...   \n",
              "\n",
              "                              path  \\\n",
              "2546  common_voice_ru_42555795.mp3   \n",
              "279   common_voice_ru_41973269.mp3   \n",
              "1510  common_voice_ru_42327869.mp3   \n",
              "1553  common_voice_ru_42405536.mp3   \n",
              "2230  common_voice_ru_42544239.mp3   \n",
              "\n",
              "                                            sentence_id  \\\n",
              "2546  dcfbc2f243aece89b99bf586adefc2238becf39f23ba60...   \n",
              "279   5939e5ac0fbe4b50bcf24d90f901e69ee50071e71be68f...   \n",
              "1510  dc5309bb107302de9a63d31cfb8255131a5b42b0cc22ae...   \n",
              "1553  dc7faf98f1e82b2f0e4ea8f8434fa4c63587a2e37045f0...   \n",
              "2230  d93b5579d81cc6b5087215517c8187a9a04b395cade88c...   \n",
              "\n",
              "                                               sentence sentence_domain  \\\n",
              "2546  В разрабатываемой технологии взаимодействие ме...             NaN   \n",
              "279   Под летним небом звезды сверкали, словно алмаз...             NaN   \n",
              "1510  Такой механизм применяется для урегулирования ...             NaN   \n",
              "1553                  Я смотрю, у вас новое назначение.             NaN   \n",
              "2230  Трансатлантическая работорговля была особенно ...             NaN   \n",
              "\n",
              "      up_votes  down_votes       age          gender  \\\n",
              "2546         0           0       NaN             NaN   \n",
              "279          0           0  thirties             NaN   \n",
              "1510         0           0  thirties  male_masculine   \n",
              "1553         0           0  thirties  male_masculine   \n",
              "2230         0           0  thirties             NaN   \n",
              "\n",
              "                                accents  variant locale  segment source  \n",
              "2546                                NaN      NaN     ru      NaN  other  \n",
              "279   Georgian accent,Грузинский акцент      NaN     ru      NaN  other  \n",
              "1510                                NaN      NaN     ru      NaN  other  \n",
              "1553                                NaN      NaN     ru      NaN  other  \n",
              "2230                                NaN      NaN     ru      NaN  other  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96fcfb33-a59a-4653-b381-5d90f57b7efc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>path</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentence_domain</th>\n",
              "      <th>up_votes</th>\n",
              "      <th>down_votes</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>accents</th>\n",
              "      <th>variant</th>\n",
              "      <th>locale</th>\n",
              "      <th>segment</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>d3f1f7c923f0522c03e865129fff2650df0b66ec0df81b...</td>\n",
              "      <td>common_voice_ru_42555795.mp3</td>\n",
              "      <td>dcfbc2f243aece89b99bf586adefc2238becf39f23ba60...</td>\n",
              "      <td>В разрабатываемой технологии взаимодействие ме...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ru</td>\n",
              "      <td>NaN</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>4a3d198ccac94aa3330809ce2eef552dec6625d1169508...</td>\n",
              "      <td>common_voice_ru_41973269.mp3</td>\n",
              "      <td>5939e5ac0fbe4b50bcf24d90f901e69ee50071e71be68f...</td>\n",
              "      <td>Под летним небом звезды сверкали, словно алмаз...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>thirties</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Georgian accent,Грузинский акцент</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ru</td>\n",
              "      <td>NaN</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1510</th>\n",
              "      <td>860c378a00fee36eb354361dae39730bfa969c53e99baf...</td>\n",
              "      <td>common_voice_ru_42327869.mp3</td>\n",
              "      <td>dc5309bb107302de9a63d31cfb8255131a5b42b0cc22ae...</td>\n",
              "      <td>Такой механизм применяется для урегулирования ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>thirties</td>\n",
              "      <td>male_masculine</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ru</td>\n",
              "      <td>NaN</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1553</th>\n",
              "      <td>860c378a00fee36eb354361dae39730bfa969c53e99baf...</td>\n",
              "      <td>common_voice_ru_42405536.mp3</td>\n",
              "      <td>dc7faf98f1e82b2f0e4ea8f8434fa4c63587a2e37045f0...</td>\n",
              "      <td>Я смотрю, у вас новое назначение.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>thirties</td>\n",
              "      <td>male_masculine</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ru</td>\n",
              "      <td>NaN</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2230</th>\n",
              "      <td>e4571c8ae7d79a96e6f28a3facacdd14a240bd3f246456...</td>\n",
              "      <td>common_voice_ru_42544239.mp3</td>\n",
              "      <td>d93b5579d81cc6b5087215517c8187a9a04b395cade88c...</td>\n",
              "      <td>Трансатлантическая работорговля была особенно ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>thirties</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ru</td>\n",
              "      <td>NaN</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96fcfb33-a59a-4653-b381-5d90f57b7efc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96fcfb33-a59a-4653-b381-5d90f57b7efc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96fcfb33-a59a-4653-b381-5d90f57b7efc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0aa2a42c-5899-4a87-acba-d3d392923253\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0aa2a42c-5899-4a87-acba-d3d392923253')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0aa2a42c-5899-4a87-acba-d3d392923253 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train_ru",
              "summary": "{\n  \"name\": \"df_train_ru\",\n  \"rows\": 2121,\n  \"fields\": [\n    {\n      \"column\": \"client_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 71,\n        \"samples\": [\n          \"86b88f48a6ef2c18cbaec64e1ae460ebb4345f52a4bd40505afd87ff18f27d159d0b6188aefb0a1b50d90fa96a86079259375d76030daf9864636a701fdc64cd\",\n          \"d3f1f7c923f0522c03e865129fff2650df0b66ec0df81bff5876b8a2c2643ca5d90d21176e624dbe7cd1775889ea83cbc9b43563e529e3d9a876c8fd1e6cea65\",\n          \"5fa6ce7c41c3bc5ed253259afe0081a640a742fdffb4f69fd8976cd327d525d96b542221f6fda3a9b7a34d7757f48e8336d3c0d805d253b6446f3c9d12ae44fb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2121,\n        \"samples\": [\n          \"common_voice_ru_42452395.mp3\",\n          \"common_voice_ru_42558913.mp3\",\n          \"common_voice_ru_42000622.mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1763,\n        \"samples\": [\n          \"db178797e26da89b5449693949c958fb4486e0a88860771f2ff01c2f0014d3be\",\n          \"d760cd6e24ee8d06049a6c272f6d6baf862826d83585f2736abebd46989b664e\",\n          \"a03cc7533a13b07018b1576d34419119bf831c9e71c764a84e57778f9fb5af37\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1763,\n        \"samples\": [\n          \"\\u0412 \\u044d\\u0442\\u043e\\u043c \\u0431\\u043e\\u043b\\u044c\\u0448\\u0430\\u044f \\u0437\\u0430\\u0441\\u043b\\u0443\\u0433\\u0430, \\u043f\\u043e\\u0436\\u0430\\u043b\\u0443\\u0439 \\u0440\\u0435\\u0448\\u0430\\u044e\\u0449\\u0430\\u044f \\u0437\\u0430\\u0441\\u043b\\u0443\\u0433\\u0430, \\u043f\\u0440\\u0435\\u0437\\u0438\\u0434\\u0435\\u043d\\u0442\\u043e\\u0432 \\u043e\\u0431\\u0435\\u0438\\u0445 \\u0441\\u0442\\u0440\\u0430\\u043d, \\u0430 \\u0442\\u0430\\u043a\\u0436\\u0435 \\u043f\\u0435\\u0440\\u0435\\u0433\\u043e\\u0432\\u043e\\u0440\\u0449\\u0438\\u043a\\u043e\\u0432.\",\n          \"\\u042f \\u043d\\u0430\\u0441\\u0442\\u043e\\u044f\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e \\u043f\\u0440\\u0438\\u0437\\u044b\\u0432\\u0430\\u044e \\u0410\\u0441\\u0441\\u0430\\u043c\\u0431\\u043b\\u0435\\u044e \\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u0442\\u044c \\u043d\\u0435\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u043e \\u0432\\u0430\\u0436\\u043d\\u044b\\u0445 \\u043c\\u0435\\u0440, \\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0435 \\u043c\\u043e\\u0433\\u043b\\u0438 \\u0431\\u044b \\u0441\\u0443\\u0449\\u0435\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e \\u0438\\u0437\\u043c\\u0435\\u043d\\u0438\\u0442\\u044c \\u043f\\u043e\\u043b\\u043e\\u0436\\u0435\\u043d\\u0438\\u0435.\",\n          \"\\u0422\\u0435\\u043c\\u043d\\u0430\\u044f \\u0438 \\u043a\\u0440\\u043e\\u0432\\u0430\\u0432\\u0430\\u044f \\u0430\\u0442\\u043c\\u043e\\u0441\\u0444\\u0435\\u0440\\u0430 \\u043c\\u0430\\u043d\\u0433\\u0438 \\u0434\\u0435\\u043b\\u0430\\u0435\\u0442 \\u0435\\u0435 \\u043e\\u0434\\u043d\\u043e\\u0439 \\u0438\\u0437 \\u0441\\u0430\\u043c\\u044b\\u0445 \\u0437\\u0430\\u043f\\u043e\\u043c\\u0438\\u043d\\u0430\\u044e\\u0449\\u0438\\u0445\\u0441\\u044f \\u0432 \\u0436\\u0430\\u043d\\u0440\\u0435.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"general\",\n          \"nature_environment,history_law_government,media_entertainment\",\n          \"history_law_government\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"up_votes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          6,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"down_votes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"twenties\",\n          \"teens\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female_feminine\",\n          \"male_masculine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accents\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"\\u0440\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439 \\u0441\\u0442\\u0430\\u043d\\u0434\\u0430\\u0440\\u0442\\u043d\\u044b\\u0439\",\n          \"\\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"variant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"locale\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"segment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_mp3_dir = '/content/cv_data/cv-corpus-21.0-delta-2025-03-14/ru/clips'\n",
        "output_wav_dir = '/content/accent-recog-slt2022/CommonAccent/data_small/wav_files'\n",
        "os.makedirs(output_wav_dir, exist_ok=True)\n",
        "\n",
        "all_files = pd.concat([df_train_ru, df_dev_ru, df_test_ru])[\"path\"].unique()\n",
        "\n",
        "# Filtering existing files\n",
        "existing_files = [f for f in all_files if os.path.exists(os.path.join(input_mp3_dir, f))]\n",
        "print(f\"Files from CSV: {len(all_files)}, found: {len(existing_files)}\")\n",
        "\n",
        "# Convverting formats\n",
        "for file in tqdm(existing_files, desc=\"Converting MP3 -> WAV\"):\n",
        "    mp3_path = os.path.join(input_mp3_dir, file)\n",
        "    wav_path = os.path.join(output_wav_dir, file.replace('.mp3', '.wav'))\n",
        "\n",
        "    try:\n",
        "        audio, sr = librosa.load(mp3_path, sr=16000, mono=True)\n",
        "        sf.write(wav_path, audio, 16000)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Could not process {file}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcyapYAZhIaa",
        "outputId": "b3a5e58a-3f04-4fa4-c0ea-c0eacdab8cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files from CSV: 3030, found: 3030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting MP3 -> WAV: 100%|██████████| 3030/3030 [06:12<00:00,  8.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "validated_path = '/content/cv_data/cv-corpus-21.0-delta-2025-03-14/ru/validated.tsv'\n",
        "other_path = '/content/cv_data/cv-corpus-21.0-delta-2025-03-14/ru/other.tsv'\n",
        "\n",
        "df_validated = pd.read_csv(validated_path, sep='\\t')\n",
        "df_other = pd.read_csv(other_path, sep='\\t')\n",
        "df_all = pd.concat([df_validated, df_other], ignore_index=True)\n",
        "\n",
        "keep_columns = [\"path\", \"sentence\", \"client_id\", \"locale\"]\n",
        "df_all = df_all[[col for col in keep_columns if col in df_all.columns]]\n",
        "\n",
        "wav_dir = '/content/accent-recog-slt2022/CommonAccent/data_small/wav_files'\n",
        "\n",
        "def build_dataset(split_df, split_name):\n",
        "    df_split = df_all[df_all[\"path\"].isin(split_df[\"path\"])].copy()\n",
        "\n",
        "    df_split[\"path\"] = df_split[\"path\"].apply(lambda x: os.path.join(wav_dir, x.replace(\".mp3\", \".wav\")))\n",
        "    df_split = df_split[df_split[\"path\"].apply(os.path.exists)]\n",
        "    df_split[\"path\"] = df_split[\"path\"].apply(lambda x: os.path.relpath(x, start=\"/content\"))\n",
        "\n",
        "    df_split.rename(columns={\n",
        "        \"sentence\": \"text\",\n",
        "        \"client_id\": \"speaker_id\",\n",
        "        \"locale\": \"language\"\n",
        "    }, inplace=True)\n",
        "\n",
        "    output_path = f\"/content/{split_name}.ru.csv\"\n",
        "    df_split.to_csv(output_path, index=False)\n",
        "    print(f\"✅ {split_name}.ru.csv saved ({len(df_split)}).\")\n",
        "\n",
        "build_dataset(df_train_ru, \"train\")\n",
        "build_dataset(df_dev_ru, \"val\")\n",
        "build_dataset(df_test_ru, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P7MRTp_lD01",
        "outputId": "e71c843c-3bb7-4412-ae90-40ce4c9a5798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ train.ru.csv saved (2121).\n",
            "✅ val.ru.csv saved (454).\n",
            "✅ test.ru.csv saved (455).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(\"/content/train.csv\").columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CBL-TjWyT1x",
        "outputId": "533dcc66-74c0-4f57-8ab9-891f3f235ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['path', 'text', 'speaker_id', 'language'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv(\"/content/train.csv\")\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "n7fQykcHoToo",
        "outputId": "54ede201-a108-46a5-dcdc-82ec2b00e0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                path  \\\n",
              "0  accent-recog-slt2022/CommonAccent/data_small/w...   \n",
              "1  accent-recog-slt2022/CommonAccent/data_small/w...   \n",
              "2  accent-recog-slt2022/CommonAccent/data_small/w...   \n",
              "3  accent-recog-slt2022/CommonAccent/data_small/w...   \n",
              "4  accent-recog-slt2022/CommonAccent/data_small/w...   \n",
              "\n",
              "                                                text  \\\n",
              "0              Особенная кошка - любимица всей семьи   \n",
              "1  Верный друг всегда поддержит в трудную минуту,...   \n",
              "2  Помечтайте о мире, где каждый человек может пр...   \n",
              "3  Читать текст и пытаться звучать похоже на ориг...   \n",
              "4  хотя все знают, что Венгрия подарила миру таки...   \n",
              "\n",
              "                                          speaker_id language  \n",
              "0  4a3d198ccac94aa3330809ce2eef552dec6625d1169508...       ru  \n",
              "1  4a3d198ccac94aa3330809ce2eef552dec6625d1169508...       ru  \n",
              "2  4a3d198ccac94aa3330809ce2eef552dec6625d1169508...       ru  \n",
              "3  4a3d198ccac94aa3330809ce2eef552dec6625d1169508...       ru  \n",
              "4  4a3d198ccac94aa3330809ce2eef552dec6625d1169508...       ru  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33e44c5f-2dbc-49bb-9dd6-b34400bc8c7e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>text</th>\n",
              "      <th>speaker_id</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>accent-recog-slt2022/CommonAccent/data_small/w...</td>\n",
              "      <td>Особенная кошка - любимица всей семьи</td>\n",
              "      <td>4a3d198ccac94aa3330809ce2eef552dec6625d1169508...</td>\n",
              "      <td>ru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>accent-recog-slt2022/CommonAccent/data_small/w...</td>\n",
              "      <td>Верный друг всегда поддержит в трудную минуту,...</td>\n",
              "      <td>4a3d198ccac94aa3330809ce2eef552dec6625d1169508...</td>\n",
              "      <td>ru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>accent-recog-slt2022/CommonAccent/data_small/w...</td>\n",
              "      <td>Помечтайте о мире, где каждый человек может пр...</td>\n",
              "      <td>4a3d198ccac94aa3330809ce2eef552dec6625d1169508...</td>\n",
              "      <td>ru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>accent-recog-slt2022/CommonAccent/data_small/w...</td>\n",
              "      <td>Читать текст и пытаться звучать похоже на ориг...</td>\n",
              "      <td>4a3d198ccac94aa3330809ce2eef552dec6625d1169508...</td>\n",
              "      <td>ru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>accent-recog-slt2022/CommonAccent/data_small/w...</td>\n",
              "      <td>хотя все знают, что Венгрия подарила миру таки...</td>\n",
              "      <td>4a3d198ccac94aa3330809ce2eef552dec6625d1169508...</td>\n",
              "      <td>ru</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33e44c5f-2dbc-49bb-9dd6-b34400bc8c7e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33e44c5f-2dbc-49bb-9dd6-b34400bc8c7e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33e44c5f-2dbc-49bb-9dd6-b34400bc8c7e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5ede7ced-718d-4cef-aeec-ab98369ebfdd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ede7ced-718d-4cef-aeec-ab98369ebfdd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5ede7ced-718d-4cef-aeec-ab98369ebfdd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 2121,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2121,\n        \"samples\": [\n          \"accent-recog-slt2022/CommonAccent/data_small/wav_files/common_voice_ru_42558816.wav\",\n          \"accent-recog-slt2022/CommonAccent/data_small/wav_files/common_voice_ru_42506949.wav\",\n          \"accent-recog-slt2022/CommonAccent/data_small/wav_files/common_voice_ru_41976906.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1763,\n        \"samples\": [\n          \"\\u0422\\u0435 \\u043f\\u043e-\\u043f\\u0440\\u0435\\u0436\\u043d\\u0435\\u043c\\u0443 \\u0441\\u0442\\u043e\\u044f\\u0442 \\u0432 \\u0441\\u0442\\u043e\\u0440\\u043e\\u043d\\u0435.\",\n          \"\\u041b\\u044e\\u043a \\u0443\\u0437\\u043d\\u0430\\u0435\\u0442, \\u0447\\u0442\\u043e \\u0435\\u0433\\u043e \\u043e\\u0442\\u0435\\u0446 \\u0431\\u044b\\u043b \\u0434\\u0436\\u0435\\u0434\\u0430\\u0435\\u043c\",\n          \"\\u0412 \\u043a\\u043e\\u0441\\u043c\\u043e\\u0441\\u0435 \\u043d\\u0435\\u0442 \\u043d\\u0438 \\u0432\\u0435\\u0440\\u0445\\u0430, \\u043d\\u0438 \\u043d\\u0438\\u0437\\u0430, \\u043d\\u0438 \\u043b\\u0435\\u0432\\u0430, \\u043d\\u0438 \\u043f\\u0440\\u0430\\u0432\\u0430.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 71,\n        \"samples\": [\n          \"d2b364fd5c6921b81afc06291354335294569bddb1a4291541fdd98180650b82d84d4ce4c4237a3159aa9a17707b927fdc266ec356b06bb56663718e9b8b93f4\",\n          \"4a3d198ccac94aa3330809ce2eef552dec6625d116950888019d1d5fbd71e82e022f2878fa2d1a4af25743f6a90ef234165fe3eaba26198c29f3afdb054ba1f8\",\n          \"eb8f878f4965468b469ed1dbc2c72b5f1f5adc83d9a476c7f122e1deb067281807e48a489438b065db3242bb911f65d944490e4f12550e1e9d887e5a93151410\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ru\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Belarusian"
      ],
      "metadata": {
        "id": "bMcW-a2YFF_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loading the dataset locally"
      ],
      "metadata": {
        "id": "NzvYzJGgRLus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #use this if you want to upload the file from colab"
      ],
      "metadata": {
        "id": "oZ19BTktL5Gm",
        "outputId": "08a4c634-1e76-438c-d83d-9a4156b26552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive_path = \"/content/drive/MyDrive/Colab Notebooks/cv-corpus-21.0-delta-2025-03-14-be.tar.gz\" #change to your location on Google Drive - look it up in the directory from the left\n",
        "#gdrive_path = \"/content/drive/MyDrive/Colab Notebooks/cv-corpus-14.0-delta-2023-06-23-be.tar.gz\" #a bigger file\n",
        "extract_path = '/content/cv_data'\n",
        "import tarfile\n",
        "\n",
        "with tarfile.open(gdrive_path, \"r:gz\") as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "\n",
        "print(\"Extraction complete.\")"
      ],
      "metadata": {
        "id": "3RTQqKC7L9VW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02fa615d-7049-4efe-e87c-14a4a57ab0dc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing from the directory\n",
        "#import tarfile\n",
        "\n",
        "#tar_path = \"/content/cv-corpus-21.0-delta-2025-03-14-be.tar.gz\" #your downloaded locally dataset\n",
        "#extract_path = \"/content/cv_data\n",
        "\n",
        "#with tarfile.open(tar_path, \"r:gz\") as tar:\n",
        "#    tar.extractall(path=extract_path)\n",
        "\n",
        "#print(\"Extraction complete.\")"
      ],
      "metadata": {
        "id": "ZThrQxQmJwQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q speechbrain==0.5.13 \\\n",
        "    transformers==4.25.1 \\\n",
        "    librosa==0.9.2 \\\n",
        "    ipdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3yeTiUBMg0p",
        "outputId": "504622fa-75a6-4802-8c94-0ea1c7e72fbb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/499.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m491.5/499.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.0/499.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "data_path = \"/content/cv_data/cv-corpus-21.0-delta-2025-03-14/be\"\n",
        "#data_path = \"/content/cv_data/cv-corpus-14.0-delta-2023-06-23/be\"\n",
        "validated_path = os.path.join(data_path, \"validated.tsv\")\n",
        "other_path = os.path.join(data_path, \"other.tsv\")\n",
        "\n",
        "df_validated = pd.read_csv(validated_path, sep='\\t')\n",
        "df_other = pd.read_csv(other_path, sep='\\t')\n",
        "\n",
        "df_validated['source'] = 'validated'\n",
        "df_other['source'] = 'other'\n",
        "\n",
        "df_combined = pd.concat([df_validated, df_other], ignore_index=True)\n",
        "\n",
        "print(f\"Validated samples: {len(df_validated)}\")\n",
        "print(f\"Other samples: {len(df_other)}\")\n",
        "print(f\"Total samples combined: {len(df_combined)}\\n\")\n",
        "\n",
        "# 70% train, 15% dev, 15% test\n",
        "df_train_be, df_temp_be = train_test_split(df_combined, test_size=0.3, random_state=42)\n",
        "df_dev_be, df_test_be = train_test_split(df_temp_be, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Train size belarusian: {len(df_train_be)}\")\n",
        "print(f\"Dev size belarusian: {len(df_dev_be)}\")\n",
        "print(f\"Test size belarusian: {len(df_test_be)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQVCdKm0OPgH",
        "outputId": "4f815391-dd60-417d-9085-a91a03f41d4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validated samples: 639\n",
            "Other samples: 7203\n",
            "Total samples combined: 7842\n",
            "\n",
            "Train size belarusian: 5489\n",
            "Dev size belarusian: 1176\n",
            "Test size belarusian: 1177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_be.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "KFZ5YK0bT3to",
        "outputId": "51ef656b-67de-424e-ae97-9702335b6d3d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              client_id  \\\n",
              "605   94066a18a2f30a5f8c3b1b93908e9bd180797803cee8ce...   \n",
              "3196  659b04f837f6b33da64c1cfd5472c09c5c611dc8dec68f...   \n",
              "3779  eb1078ce1c52d7b2a283533cba8fed0042df12e131514f...   \n",
              "1468  98da89725e47cf9fd22a756f540a6d33817008d6624b86...   \n",
              "5784  659b04f837f6b33da64c1cfd5472c09c5c611dc8dec68f...   \n",
              "\n",
              "                              path  \\\n",
              "605   common_voice_be_42076166.mp3   \n",
              "3196  common_voice_be_42139499.mp3   \n",
              "3779  common_voice_be_42250413.mp3   \n",
              "1468  common_voice_be_41974615.mp3   \n",
              "5784  common_voice_be_42498438.mp3   \n",
              "\n",
              "                                            sentence_id  \\\n",
              "605   b6b5d55f6e367536a6e794e0679d5ee421914d9fe8baa1...   \n",
              "3196  b6ffebb4bb1af260ed3c3da87ffdc46b82da959c9e08d4...   \n",
              "3779  b7802586d0187e30f20e7497341dd5ddc6e34cadf47ab9...   \n",
              "1468  b5fa7dc5a1765f5ea91af9365fe90116edd2e662ad0fed...   \n",
              "5784  b932fcdf2f0126a30008c8c5d9beedbf58e9dd3d8f3c05...   \n",
              "\n",
              "                                               sentence sentence_domain  \\\n",
              "605   Да апошняга моманту цяжка было сказаць, хто ст...             NaN   \n",
              "3196                  Дзе менавіта, пакуль няма ведама.             NaN   \n",
              "3779  Аднак для навучальнага працэсу наяўнасць мален...             NaN   \n",
              "1468  Добра, што мы можам гандляваць ва ўсіх напрамках.             NaN   \n",
              "5784  Ён стаіць амаль у цэнтры райцэнтра, побач прах...             NaN   \n",
              "\n",
              "      up_votes  down_votes  age gender accents  variant locale  segment  \\\n",
              "605          2           0  NaN    NaN     NaN      NaN     be      NaN   \n",
              "3196         0           0  NaN    NaN     NaN      NaN     be      NaN   \n",
              "3779         0           0  NaN    NaN     NaN      NaN     be      NaN   \n",
              "1468         0           0  NaN    NaN     NaN      NaN     be      NaN   \n",
              "5784         1           0  NaN    NaN     NaN      NaN     be      NaN   \n",
              "\n",
              "         source  \n",
              "605   validated  \n",
              "3196      other  \n",
              "3779      other  \n",
              "1468      other  \n",
              "5784      other  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-caf08ef0-6546-4cc7-b56a-24523084c585\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>path</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentence_domain</th>\n",
              "      <th>up_votes</th>\n",
              "      <th>down_votes</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>accents</th>\n",
              "      <th>variant</th>\n",
              "      <th>locale</th>\n",
              "      <th>segment</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>605</th>\n",
              "      <td>94066a18a2f30a5f8c3b1b93908e9bd180797803cee8ce...</td>\n",
              "      <td>common_voice_be_42076166.mp3</td>\n",
              "      <td>b6b5d55f6e367536a6e794e0679d5ee421914d9fe8baa1...</td>\n",
              "      <td>Да апошняга моманту цяжка было сказаць, хто ст...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>be</td>\n",
              "      <td>NaN</td>\n",
              "      <td>validated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3196</th>\n",
              "      <td>659b04f837f6b33da64c1cfd5472c09c5c611dc8dec68f...</td>\n",
              "      <td>common_voice_be_42139499.mp3</td>\n",
              "      <td>b6ffebb4bb1af260ed3c3da87ffdc46b82da959c9e08d4...</td>\n",
              "      <td>Дзе менавіта, пакуль няма ведама.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>be</td>\n",
              "      <td>NaN</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3779</th>\n",
              "      <td>eb1078ce1c52d7b2a283533cba8fed0042df12e131514f...</td>\n",
              "      <td>common_voice_be_42250413.mp3</td>\n",
              "      <td>b7802586d0187e30f20e7497341dd5ddc6e34cadf47ab9...</td>\n",
              "      <td>Аднак для навучальнага працэсу наяўнасць мален...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>be</td>\n",
              "      <td>NaN</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1468</th>\n",
              "      <td>98da89725e47cf9fd22a756f540a6d33817008d6624b86...</td>\n",
              "      <td>common_voice_be_41974615.mp3</td>\n",
              "      <td>b5fa7dc5a1765f5ea91af9365fe90116edd2e662ad0fed...</td>\n",
              "      <td>Добра, што мы можам гандляваць ва ўсіх напрамках.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>be</td>\n",
              "      <td>NaN</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5784</th>\n",
              "      <td>659b04f837f6b33da64c1cfd5472c09c5c611dc8dec68f...</td>\n",
              "      <td>common_voice_be_42498438.mp3</td>\n",
              "      <td>b932fcdf2f0126a30008c8c5d9beedbf58e9dd3d8f3c05...</td>\n",
              "      <td>Ён стаіць амаль у цэнтры райцэнтра, побач прах...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>be</td>\n",
              "      <td>NaN</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caf08ef0-6546-4cc7-b56a-24523084c585')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-caf08ef0-6546-4cc7-b56a-24523084c585 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-caf08ef0-6546-4cc7-b56a-24523084c585');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c08c2644-bd68-41b1-be6e-ab10a385ef55\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c08c2644-bd68-41b1-be6e-ab10a385ef55')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c08c2644-bd68-41b1-be6e-ab10a385ef55 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train_be",
              "summary": "{\n  \"name\": \"df_train_be\",\n  \"rows\": 5489,\n  \"fields\": [\n    {\n      \"column\": \"client_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 59,\n        \"samples\": [\n          \"94066a18a2f30a5f8c3b1b93908e9bd180797803cee8ceb2223720326837a49212dfabfd1839ed0e860fafcbd03a5c26d4e82cd6be97aa699a2888e0fdce42fd\",\n          \"a4d29db93aa3c123886b56bf205384637109b26e020db3f76a0365d785234fad658dd013bf176c8cf32f80254b84defff211bdef40d6129f818d9b18bf3112c6\",\n          \"2f1e9e2e51d321ed2f9ea32e3e10fb73a8111fbcd902086ead986f302e7470108fbb680cce411dd073ab96ec5bf0c9b3a76ff840cb6230dd890fb8ed3fed1f36\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5489,\n        \"samples\": [\n          \"common_voice_be_42628832.mp3\",\n          \"common_voice_be_42673106.mp3\",\n          \"common_voice_be_42261296.mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5457,\n        \"samples\": [\n          \"b71e515e7fff52631d4830824e09e304a21a32e80d685dbd5f4df58268a294cf\",\n          \"b53c67979b9dcc8919b9cd4ee29d3e2a2d704588005854f4fceeac35304664e8\",\n          \"b85740ddb239793eb88eb2a0b11eaa454c2263bc8e4ef8c8794e51bf058ce650\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5457,\n        \"samples\": [\n          \"\\u0423 \\u044e\\u043d\\u0430\\u0446\\u0442\\u0432\\u0435 \\u0437\\u0430\\u0439\\u043c\\u0430\\u043b\\u0430\\u0441\\u044f \\u0441\\u043a\\u043e\\u043a\\u0430\\u043c\\u0456 \\u043d\\u0430 \\u0431\\u0430\\u0442\\u0443\\u0446\\u0435.\",\n          \"\\u0425\\u043b\\u0443\\u0441\\u043d\\u0456 \\u043c\\u043e\\u0436\\u043d\\u0430 \\u0441\\u0443\\u043f\\u0440\\u0430\\u0446\\u044c\\u0441\\u0442\\u0430\\u044f\\u0446\\u044c \\u0442\\u043e\\u043b\\u044c\\u043a\\u0456 \\u0442\\u043e\\u043b\\u044c\\u043a\\u0456 \\u043f\\u0440\\u0430\\u045e\\u0434\\u0430\\u0439.\",\n          \"\\u0421\\u0430\\u043f\\u0440\\u0430\\u045e\\u0434\\u044b, \\u043d\\u0430\\u0432\\u043e\\u0448\\u0442\\u0430 \\u043d\\u0430\\u043c \\u0442\\u0430\\u044f \\u0444\\u0430\\u0440\\u0431\\u0430?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"history_law_government\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"up_votes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"down_votes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"twenties\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female_feminine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accents\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\u0411\\u0435\\u0437 \\u0430\\u043a\\u0446\\u044d\\u043d\\u0442\\u0443.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"variant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"locale\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"segment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train_be[\"accents\"])"
      ],
      "metadata": {
        "id": "i7xI3fPB-QU4",
        "outputId": "42b09bff-3b71-4dc3-aac5-97f955003f4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "605     NaN\n",
            "3196    NaN\n",
            "3779    NaN\n",
            "1468    NaN\n",
            "5784    NaN\n",
            "       ... \n",
            "5226    NaN\n",
            "5390    NaN\n",
            "860     NaN\n",
            "7603    NaN\n",
            "7270    NaN\n",
            "Name: accents, Length: 5489, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "be_accents_df = df_train_be[\"accents\"].dropna()\n",
        "print(be_accents_df)"
      ],
      "metadata": {
        "id": "EK5k-a7G-p6i",
        "outputId": "c8149337-43cf-4cb8-d5c3-902ec4aaadd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4935        трасянка\n",
            "416         трасянка\n",
            "446         трасянка\n",
            "4704        трасянка\n",
            "4932        трасянка\n",
            "            ...     \n",
            "4933        трасянка\n",
            "4929        трасянка\n",
            "5088    Без акцэнту.\n",
            "4931        трасянка\n",
            "4659        трасянка\n",
            "Name: accents, Length: 90, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(be_accents_df.value_counts())"
      ],
      "metadata": {
        "id": "NiuUxbv0BFpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## processing audio"
      ],
      "metadata": {
        "id": "U0vnPWT7fUo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In my file I had mp3 files instead of wav files, so I have to convert them to be processable by speechbrain (may be I have not just found the information about its ability to process mp3 files)"
      ],
      "metadata": {
        "id": "XvJHFZo7WrI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import shutil\n",
        "\n",
        "\n",
        "input_mp3_dir = '/content/cv_data/cv-corpus-21.0-delta-2025-03-14/be/clips'  # source .mp3 directory\n",
        "output_wav_dir = '/content/accent-recog-slt2022/CommonAccent/data_small/wav_files'  # target wav directory\n",
        "os.makedirs(output_wav_dir, exist_ok=True)\n",
        "\n",
        "# You can collect all file names from your filtered CSVs\n",
        "all_files = pd.concat([df_train_be, df_dev_be, df_test_be])[\"path\"].unique()\n",
        "\n",
        "# Loop through all .mp3 files and convert\n",
        "for file in os.listdir(input_mp3_dir):\n",
        "    if file.endswith('.mp3'):\n",
        "        mp3_path = os.path.join(input_mp3_dir, file)\n",
        "        wav_path = os.path.join(output_wav_dir, file.replace('.mp3', '.wav'))\n",
        "\n",
        "        try:\n",
        "            # Load MP3 using librosa (automatically resamples and converts to mono)\n",
        "            audio, sr = librosa.load(mp3_path, sr=16000, mono=True)\n",
        "            # Save as WAV 16kHz mono\n",
        "            sf.write(wav_path, audio, 16000)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to process {file}: {e}\")"
      ],
      "metadata": {
        "id": "zV1OGTYbg-0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from pydub import AudioSegment\n",
        "#import os\n",
        "#from tqdm import tqdm\n",
        "\n",
        "# mp3_dir = \"/content/cv_data/cv-corpus-14.0-delta-2023-06-23/be/clips\"\n",
        "# output_dir = \"/content/accent-recog-slt2022/CommonAccent/data/wav_files\"\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# # You can collect all file names from your filtered CSVs\n",
        "# all_files = pd.concat([df_train_be, df_dev_be, df_test_be])[\"path\"].unique()\n",
        "\n",
        "# for mp3_file in tqdm(all_files):\n",
        "#     mp3_path = os.path.join(mp3_dir, mp3_file)\n",
        "#     wav_path = os.path.join(output_dir, mp3_file.replace(\".mp3\", \".wav\"))\n",
        "\n",
        "#     if not os.path.exists(mp3_path):\n",
        "#         continue  # skip if the file isn't found\n",
        "\n",
        "#     try:\n",
        "#         audio = AudioSegment.from_mp3(mp3_path)\n",
        "#         audio.export(wav_path, format=\"wav\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Failed: {mp3_file} -> {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "bWj5ehbhWxxf",
        "outputId": "4efe90c7-5283-44d0-e5fb-ce332f67464c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 8437/54028 [47:15<4:15:24,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-54-591632987.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_mp3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp3_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_mp3\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_mp3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mp3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmediainfo_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_ahead_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_ahead_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             audio_streams = [x for x in info['streams']\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydub/utils.py\u001b[0m in \u001b[0;36mmediainfo_json\u001b[0;34m(filepath, read_ahead_limit)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprober\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-of'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'json'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcommand_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdin_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdin_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wav_folder = output_wav_dir  # path to saved .wav files\n",
        "for df in [df_train_be, df_dev_be, df_test_be]:\n",
        "    df[\"wav\"] = df[\"path\"].apply(lambda x: os.path.join(wav_folder, x.replace(\".mp3\", \".wav\")))"
      ],
      "metadata": {
        "id": "XF_BkFBGW8Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_be.head()"
      ],
      "metadata": {
        "id": "7FRiK4nhZXqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to the path your later code expects\n",
        "output_dir = \"/content/accent-recog-slt2022/CommonAccent/data\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "df_train_be.to_csv(os.path.join(output_dir, \"train.csv\"), index=False)\n",
        "df_dev_be.to_csv(os.path.join(output_dir, \"dev.csv\"), index=False)\n",
        "df_test_be.to_csv(os.path.join(output_dir, \"test.csv\"), index=False)"
      ],
      "metadata": {
        "id": "r6OgiuxoZUPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/data_small.zip /content/accent-recog-slt2022/CommonAccent/data_small\n",
        "from google.colab import files\n",
        "files.download(\"/content/data_small.zip\")"
      ],
      "metadata": {
        "id": "ODxhyxnoewnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R /content/accent-recog-slt2022/CommonAccent/data_small/wav_files /content/drive/MyDrive/.../data/wav"
      ],
      "metadata": {
        "id": "H0fVjQ8Sgq8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accent extraction - failure\n",
        "\n",
        "common_accent_prepare.py is a script in the loaded repo\n",
        "it is situated here: /content/accent-recog-slt2022/CommonAccent/common_accent_prepare.py\n",
        "\n",
        "```\n",
        "def prepare_common_accent(\n",
        "        data_folder,\n",
        "        save_folder,\n",
        "        accented_letters=False,\n",
        "        language=\"en\",        \n",
        "        skip_prep=False,\n",
        "    ):\n",
        "\n",
        "    \"\"\"\n",
        "    Prepares the csv files for the CommonAccent dataset for Accent Classification.\n",
        "    Download: https://commonvoice.mozilla.org/en/datasets\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    data_folder : str\n",
        "        Path to the folder where the CommonAccent dataset for Accent Classification is stored.\n",
        "        This path should include the multi: /datasets/CommonAccent\n",
        "    save_folder : str\n",
        "        The directory where to store the csv files.\n",
        "    max_duration : int, optional\n",
        "        Max duration (in seconds) of training uterances.\n",
        "    accented_letters : bool, optional\n",
        "        Defines if accented letters will be kept as individual letters or\n",
        "        transformed to the closest non-accented letters.\n",
        "    language: str\n",
        "        Specify the language for text normalization.        \n",
        "    skip_prep: bool\n",
        "        If True, skip data preparation.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> from recipes.CommonAccent.common_accent_prepare import prepare_common_accent\n",
        "    >>> data_folder = '/datasets/CommonAccent'\n",
        "    >>> save_folder = 'exp/CommonAccent_exp'\n",
        "    >>> prepare_common_accent(\\\n",
        "            data_folder,\\\n",
        "            save_folder,\\\n",
        "            skip_prep=False\\\n",
        "        )\n",
        "    \"\"\"\n",
        "```\n"
      ],
      "metadata": {
        "id": "4IY89c7CIqIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/accent-recog-slt2022\")\n",
        "\n",
        "from CommonAccent.common_accent_prepare import prepare_common_accent\n",
        "\n",
        "prepare_common_accent(\n",
        "    data_folder=\"/content/cv_data/\",\n",
        "    save_folder=\"/content/common_accent_output\",\n",
        "    language=\"be\",\n",
        "    skip_prep=False\n",
        ")"
      ],
      "metadata": {
        "id": "F79x36GGn88O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "d735b4ac-cf7c-4376-b618-e91700e0fa5e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/cv_data/be'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-21-3604352227.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mCommonAccent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon_accent_prepare\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare_common_accent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m prepare_common_accent(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdata_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/cv_data/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msave_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/common_accent_output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/accent-recog-slt2022/CommonAccent/common_accent_prepare.py\u001b[0m in \u001b[0;36mprepare_common_accent\u001b[0;34m(data_folder, save_folder, accented_letters, language, skip_prep)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# Additional checks to make sure the data folder contains Common Accent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mcheck_common_accent_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Audio files extensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/accent-recog-slt2022/CommonAccent/common_accent_prepare.py\u001b[0m in \u001b[0;36mcheck_common_accent_folder\u001b[0;34m(data_folder, language)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;31m# Checking if at least two accents are present in the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"train.tsv\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/cv_data/be'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python common_accent_prepare.py --language \"be\" /content/cv_data /content/common_accent_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxbTh_Vnh9_b",
        "outputId": "7668f949-504d-40c8-c185-4f8fd03f1c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/accent-recog-slt2022/CommonAccent/common_accent_prepare.py\", line 570, in <module>\n",
            "    main()\n",
            "  File \"/content/accent-recog-slt2022/CommonAccent/common_accent_prepare.py\", line 464, in main\n",
            "    prepare_common_accent(args.cv_folder, args.output_folder, language=args.language)\n",
            "  File \"/content/accent-recog-slt2022/CommonAccent/common_accent_prepare.py\", line 169, in prepare_common_accent\n",
            "    check_common_accent_folder(data_folder, language=language)\n",
            "  File \"/content/accent-recog-slt2022/CommonAccent/common_accent_prepare.py\", line 440, in check_common_accent_folder\n",
            "    raise FileNotFoundError(err_msg)\n",
            "FileNotFoundError: /content/cv_data/be must have at least 'train.tsv' file in it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunatlelly, the scripts doen ot have an option for our chosen langauge, so we decided to focus on just langauge recognition of Russian, Belarusian and Serbian"
      ],
      "metadata": {
        "id": "8Ec5DfTcH7DD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: loading from HuggingFace"
      ],
      "metadata": {
        "id": "DXTmepMXROnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "download_data_hf.py is a script in the loaded repo\n",
        "it is situated here: /content/accent-recog-slt2022/CommonAccent/download_data_hf.py\n",
        "\n",
        "**use the code from HugginFace and the number of the dataset you need, e.g.19  as in the script**\n",
        "https://huggingface.co/datasets/fsicoli/common_voice_19_0\n",
        "\n",
        "\n",
        "```\n",
        "\"\"\"\n",
        "Script to download the CommonVoice dataset using Hugging Face\n",
        "\n",
        "At Hugging Face: https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0\n",
        "Download the dataset: https://commonvoice.mozilla.org/en/datasets\n",
        "\n",
        "def prepare_cv_from_hf(output_folder, language=\"en\"):\n",
        "    \"\"\" function to prepare the datasets in <output-folder> \"\"\"\n",
        "\n",
        "    output_folder = os.path.join(output_folder, language)\n",
        "    # create the output folder: in case is not present\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Prepare the the common voice dataset in streaming mode\n",
        "    # common_voice_ds = load_dataset(_COMMON_VOICE_FOLDER, language, streaming=True)\n",
        "    common_voice_ds = load_dataset(\"fsicoli/common_voice_19_0\", language, streaming=True, trust_remote_code=True)\n",
        "\n",
        "    !!!!\n",
        "    it uses here already a dataset\n",
        "\n",
        "    # just select relevant splits: train/validation/test set\n",
        "    splits = [\"train\", \"validation\", \"test\"]\n",
        "    common_voice = {}\n",
        "    \n",
        "    # load, prepare and filter each split in streaming mode:\n",
        "    for split in splits:\n",
        "        # filter out samples without accent\n",
        "        ds = common_voice_ds[split].filter( lambda x: x['accent'] != '')\n",
        "        common_voice[split] = ds\n",
        "        \n",
        "    for dataset in common_voice:\n",
        "        csv_lines = []\n",
        "        # Starting index\n",
        "        idx = 0\n",
        "        for sample in common_voice[dataset]:\n",
        "            # get path and utt_id\n",
        "            mp3_path = sample['path']\n",
        "            utt_id = mp3_path.split(\".\")[-2].split(\"/\")[-1]            \n",
        "            \n",
        "            # Create a row with metadata + transcripts\n",
        "            csv_line = [\n",
        "                idx,  # ID\n",
        "                utt_id,  # Utterance ID\n",
        "                mp3_path,  # File name\n",
        "                sample[\"locale\"],\n",
        "                sample[\"accent\"],\n",
        "                sample[\"age\"],\n",
        "                sample[\"gender\"],\n",
        "                sample[\"sentence\"], # transcript\n",
        "            ]\n",
        "\n",
        "            # Adding this line to the csv_lines list\n",
        "            csv_lines.append(csv_line)\n",
        "            # Increment index\n",
        "            idx += 1\n",
        "\n",
        "        # CSV column titles\n",
        "        csv_header = [\"idx\", \"utt_id\", \"mp3_path\", \"language\", \"accent\", \"age\", \"gender\", \"transcript\"]\n",
        "        # Add titles to the list at indexx 0\n",
        "        csv_lines.insert(0, csv_header)\n",
        "\n",
        "        # Writing the csv lines\n",
        "        csv_file = os.path.join(output_folder, dataset+'.tsv')\n",
        "\n",
        "        with open(csv_file, mode=\"w\", encoding=\"utf-8\") as csv_f:\n",
        "            csv_writer = csv.writer(\n",
        "                csv_f, delimiter=\"\\t\", quotechar='\"', quoting=csv.QUOTE_MINIMAL\n",
        "            )\n",
        "            for line in csv_lines:\n",
        "                csv_writer.writerow(line)\n",
        "    print(f\"Prepare CommonVoice: for {language} in {output_folder}\")\n",
        "\n",
        "def main():\n",
        "    # read input from CLI, you need to run it from the command lind\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # reporting vars\n",
        "    parser.add_argument(\n",
        "        \"--language\",\n",
        "        type=str,\n",
        "        default='en',\n",
        "        help=\"Language to load\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"output_folder\",\n",
        "        help=\"path of the output folder to store the csv files for each split\",\n",
        "    )\n",
        "    args = parser.parse_args()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "tjn_F7-cRozj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**So, the script loads already one dataset\n",
        "    common_voice_ds = load_dataset(\"fsicoli/common_voice_19_0\", language, streaming=True, trust_remote_code=True), therefore you can run the cell below the same as it was in the original notebook.\n",
        "    If you need, however, abother dataset, e.g. wit hmore audio files, you need copy the code above and specify it and run the code without a script but your code in the cells**"
      ],
      "metadata": {
        "id": "DOnFOrZ99Slu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from datasets import load_dataset\n",
        "#common_voice_ds = load_dataset(\"mozilla-foundation/common_voice_19_0\", \"be\")"
      ],
      "metadata": {
        "id": "0snm1YFum2sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_cv_from_hf(output_folder, language=\"en\"):\n",
        "\n",
        "    output_folder = os.path.join(output_folder, language)\n",
        "    # create the output folder: in case is not present\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Prepare the the common voice dataset in streaming mode\n",
        "    common_voice_ds = load_dataset(_COMMON_VOICE_FOLDER, language, streaming=True)\n",
        "    #common_voice_ds = load_dataset(\"fsicoli/common_voice_19_0\", language, streaming=True, trust_remote_code=True)\n",
        "\n",
        "    # just select relevant splits: train/validation/test set\n",
        "    splits = [\"train\", \"validation\", \"test\"]\n",
        "    common_voice = {}\n",
        "\n",
        "    # load, prepare and filter each split in streaming mode:\n",
        "    for split in splits:\n",
        "        # filter out samples without accent\n",
        "        ds = common_voice_ds[split].filter( lambda x: x['accent'] != '')\n",
        "        common_voice[split] = ds\n",
        "\n",
        "    for dataset in common_voice:\n",
        "        csv_lines = []\n",
        "        # Starting index\n",
        "        idx = 0\n",
        "        for sample in common_voice[dataset]:\n",
        "            # get path and utt_id\n",
        "            mp3_path = sample['path']\n",
        "            utt_id = mp3_path.split(\".\")[-2].split(\"/\")[-1]\n",
        "\n",
        "            # Create a row with metadata + transcripts\n",
        "            csv_line = [\n",
        "                idx,  # ID\n",
        "                utt_id,  # Utterance ID\n",
        "                mp3_path,  # File name\n",
        "                sample[\"locale\"],\n",
        "                sample[\"accent\"],\n",
        "                sample[\"age\"],\n",
        "                sample[\"gender\"],\n",
        "                sample[\"sentence\"], # transcript\n",
        "            ]\n",
        "\n",
        "            # Adding this line to the csv_lines list\n",
        "            csv_lines.append(csv_line)\n",
        "            # Increment index\n",
        "            idx += 1\n",
        "\n",
        "        # CSV column titles\n",
        "        csv_header = [\"idx\", \"utt_id\", \"mp3_path\", \"language\", \"accent\", \"age\", \"gender\", \"transcript\"]\n",
        "        # Add titles to the list at indexx 0\n",
        "        csv_lines.insert(0, csv_header)\n",
        "\n",
        "        # Writing the csv lines\n",
        "        csv_file = os.path.join(output_folder, dataset+'.tsv')\n",
        "\n",
        "        with open(csv_file, mode=\"w\", encoding=\"utf-8\") as csv_f:\n",
        "            csv_writer = csv.writer(\n",
        "                csv_f, delimiter=\"\\t\", quotechar='\"', quoting=csv.QUOTE_MINIMAL\n",
        "            )\n",
        "            for line in csv_lines:\n",
        "                csv_writer.writerow(line)\n",
        "    print(f\"Prepare CommonVoice: for {language} in {output_folder}\")"
      ],
      "metadata": {
        "id": "ixQ5d9XfPx1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare_cv_from_hf(\"/content/cv_data\", language=\"be\", data_dir=\"/content/cv_data/cv-corpus-14.0-delta-2023-06-23/be\") still loads the HugginFace"
      ],
      "metadata": {
        "id": "f-FkYsWMMJd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!python /content/accent-recog-slt2022/CommonAccent/download_data_hf.py --language \"be\" /content/cv_data #loads friscoli/common_voice 19\n",
        "\n",
        "#it is an original code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FTuIFlzm_Ue",
        "outputId": "7940c43e-538c-4cd5-dea7-7ac97be875a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/accent-recog-slt2022/CommonAccent/download_data_hf.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Paths\n",
        "data_path = \"/content/accent-recog-slt2022/CommonAccent/data/\"\n",
        "audio_root = \"/content/cv_data/cv-corpus-21.0-delta-2025-03-14/be/clips/\"\n",
        "save_dir = os.path.join(data_path, \"wav_files\")\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Load CSVs\n",
        "df_train = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
        "df_test = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
        "df_dev = pd.read_csv(os.path.join(data_path, \"dev.csv\"))\n",
        "\n",
        "# Combine all file references\n",
        "all_files = pd.concat([df_train, df_test, df_dev])\n",
        "unique_filenames = all_files[\"wav\"].apply(os.path.basename).unique()\n",
        "\n",
        "# Convert and save as .wav\n",
        "for file_name in tqdm(unique_filenames, desc=\"Converting audio\"):\n",
        "    mp3_path = os.path.join(audio_root, file_name)\n",
        "    if not os.path.isfile(mp3_path):\n",
        "        print(f\"Missing file: {mp3_path}\")\n",
        "        continue\n",
        "    try:\n",
        "        waveform, sample_rate = torchaudio.load(mp3_path)\n",
        "        wav_path = os.path.join(save_dir, file_name.replace(\".mp3\", \".wav\"))\n",
        "        torchaudio.save(wav_path, waveform, sample_rate)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {mp3_path}: {e}\")"
      ],
      "metadata": {
        "id": "AJRhPfd2J6yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "from datasets import load_dataset\n",
        "\n",
        "data_path = \"/content/accent-recog-slt2022/CommonAccent/data/\"\n",
        "\n",
        "# Load CSV\n",
        "csv_path_train = data_path + \"train.csv\"\n",
        "df_train = pd.read_csv(csv_path_train)\n",
        "file_list_train = list(set(df_train['wav']))\n",
        "\n",
        "csv_path_test = data_path + \"test.csv\"\n",
        "df_test = pd.read_csv(csv_path_test)\n",
        "file_list_test = list(set(df_test['wav']))\n",
        "\n",
        "csv_path_dev = data_path + \"dev.csv\"\n",
        "df_dev = pd.read_csv(csv_path_dev)\n",
        "file_list_dev = list(set(df_dev['wav']))\n",
        "\n",
        "# Set save directory\n",
        "save_dir = data_path + \"wav_files\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Load dataset in streaming mode\n",
        "language = \"be\"  # or whatever language code you're using\n",
        "cv_11_be_train = load_dataset(\"mozilla-foundation/common_voice_11_0\", language, streaming=True, split=\"train\", trust_remote_code=True)\n",
        "print(next(iter(cv_11_be_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad6a31e-3f22-402f-fd92-e8410005b469",
        "id": "J9dhLrqeFNvM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Reading metadata...: 171388it [00:07, 23662.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'client_id': 'c14f21cacf2b7701ad0bead0dd1b31ec9d3a1557708e446de55e98b4b470cf31072c82543e5ba518c5c187a91868878a4e32727054a3dd94f9df41c9a13d8c62', 'path': 'it_train_0/common_voice_it_17415777.mp3', 'audio': {'path': 'it_train_0/common_voice_it_17415777.mp3', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
            "       -1.61342832e-05, -1.57291943e-05, -1.16234423e-05]), 'sampling_rate': 48000}, 'sentence': \"Il marchese aveva già moglie in quell'epoca?\", 'up_votes': 3, 'down_votes': 0, 'age': '', 'gender': '', 'accent': '', 'locale': 'it', 'segment': '', 'variant': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_11_be_dev = load_dataset(\"mozilla-foundation/common_voice_11_0\", language, streaming=False, split=\"validation\", trust_remote_code=True)\n",
        "cv_11_be_test = load_dataset(\"mozilla-foundation/common_voice_11_0\", language, streaming=False, split=\"test\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "4Z2evoZ9FNvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Count entries per accent\n",
        "accent_counts = df_train['accent'].value_counts()\n",
        "\n",
        "# Print the result\n",
        "print(accent_counts)\n",
        "\n",
        "# select randomly max 300 samples for each accent that has more than 300 samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003c3702-9ce5-40c1-8950-9693771089f4",
        "id": "myZLU5jiFNvM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accent\n",
            "TENDENTE AL SICULO MA NON MARCATO    1801\n",
            "BASILICATA TRENTINO                  1801\n",
            "VENETO                               1393\n",
            "MERIDIONALE                           134\n",
            "EMILIANO                               91\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a common dataset (be + ru + ser)\n",
        "\n",
        "I have deleted code for balancing because we don't need it. Instead we need to combine our train/test/val sets, so that we coul train the model in the next step.\n",
        "\n",
        "My russian CSVs contain the following: path, text, speaker_id, language\n"
      ],
      "metadata": {
        "id": "xRW333kiUKTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "base_path = \"/content/accent-recog-slt2022/CommonAccent/data\"\n",
        "\n",
        "df_train_ru = pd.read_csv(\"/content/train.csv\")\n",
        "df_val_ru = pd.read_csv(\"/content/val.csv\")\n",
        "df_test_ru = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "df_train_be = pd.read_csv(os.path.join(base_path, \"train_be.csv\"))\n",
        "df_val_be = pd.read_csv(os.path.join(base_path, \"val_be.csv\"))\n",
        "df_test_be = pd.read_csv(os.path.join(base_path, \"test_be.csv\"))\n",
        "\n",
        "df_train_sr = pd.read_csv(os.path.join(base_path, \"train_sr.csv\"))\n",
        "df_val_sr = pd.read_csv(os.path.join(base_path, \"val_sr.csv\"))\n",
        "df_test_sr = pd.read_csv(os.path.join(base_path, \"test_sr.csv\"))\n"
      ],
      "metadata": {
        "id": "SrsPePE918p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_all = pd.concat([df_train_ru, df_train_be, df_train_sr], ignore_index=True)\n",
        "df_val_all = pd.concat([df_val_ru, df_val_be, df_val_sr], ignore_index=True)\n",
        "df_test_all = pd.concat([df_test_ru, df_test_be, df_test_sr], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "MhAxcSYj67PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"/content/accent-recog-slt2022/CommonAccent/data_all\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "df_train_all.to_csv(os.path.join(output_path, \"train.csv\"), index=False)\n",
        "df_val_all.to_csv(os.path.join(output_path, \"val.csv\"), index=False)\n",
        "df_test_all.to_csv(os.path.join(output_path, \"test.csv\"), index=False)\n",
        "\n",
        "print(\"✅ All CSVs are combined and saved\")\n"
      ],
      "metadata": {
        "id": "txMV3h8F6-FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training"
      ],
      "metadata": {
        "id": "XyNqehXCT2wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas==2.2.2 \\\n",
        "    huggingface_hub>=0.7.0 \\\n",
        "    hyperpyyaml==0.0.1 \\\n",
        "    joblib \\\n",
        "    numpy==2.0.2 \\\n",
        "    packaging \\\n",
        "    pre-commit==2.3.0 \\\n",
        "    sentencepiece>=0.1.91 \\\n",
        "    SoundFile \\\n",
        "    tqdm"
      ],
      "metadata": {
        "id": "0OGFpYuJTLLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTnWihC0TLLu"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2363280-227e-4528-f9b2-90061f883fc8",
        "id": "-ieiVxJUT7iF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./run_accent_id_ecapa_tdnn.sh: Permission denied\n"
          ]
        }
      ],
      "source": [
        "!./run_accent_id_ecapa_tdnn.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the correct pretrained_path: /content/accent-recog-slt2022/CommonAccent/results/ECAPA-TDNN/EN/spkrec-ecapa-voxceleb/1986/save/\n",
        "# and load_folder: !ref <pretrained_path>/CKPT+2025-05-15+09-43-30+00\n",
        "# in the yaml file!\n",
        "# if run is successful, it will create an analysis folder (in your results folder)\n",
        "!python accent_id/inference.py accent_id/hparams/inference_ecapa_tdnn.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d01ebb-0300-4419-c3ad-9bc9902edcad",
        "id": "Fr3KYxN2T7iF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/analysis\n",
            "speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n",
            "speechbrain.pretrained.fetching - Fetch embedding_model.ckpt: Using existing file/symlink in model_checkpoints/embedding_model.ckpt.\n",
            "speechbrain.pretrained.fetching - Fetch classifier.ckpt: Using existing file/symlink in model_checkpoints/classifier.ckpt.\n",
            "speechbrain.pretrained.fetching - Fetch accent_encoder.txt: Using existing file/symlink in model_checkpoints/label_encoder.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: embedding_model, classifier, label_encoder\n",
            "speechbrain.core - Info: device arg from hparam file is used\n",
            "speechbrain.core - 20.8M trainable parameters in AccID_inf\n",
            "100% 5/5 [00:02<00:00,  1.88it/s]\n",
            "100% 5/5 [00:02<00:00,  2.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation with confusion matrix, error rate, precision, and F1-score"
      ],
      "metadata": {
        "id": "ED59kUemC3jW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## visualisation wit t-sne"
      ],
      "metadata": {
        "id": "SrJsf6iCUma6"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}